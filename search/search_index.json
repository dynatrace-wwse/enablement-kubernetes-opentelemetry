{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. About","text":""},{"location":"#kubernetes-opentelemetry","title":"Kubernetes OpenTelemetry","text":"<p>Support Policy - experiment, share feedback, and help shape the future</p> <p>This repository is part of an enablement project created by the Center of Excellence at Dynatrace. Our mission is to empower you to explore and adopt these resources to accelerate innovation. Support is community-driven and provided exclusively via GitHub Issues.</p> <p>We will make every effort to assist and address reported problems, but please note:</p> <ul> <li>The materials are provided \u201cas-is\u201d, without any warranties or guarantees.</li> <li>Use of this technology is at your own discretion and risk.</li> </ul> <p>We encourage you to experiment, share feedback, and help shape the future. Start building today!</p>"},{"location":"#lab-overview","title":"Lab Overview","text":"<p>During this hands-on training, we\u2019ll learn how to capture logs, traces, and metrics from Kubernetes using OpenTelemetry and ship them to Dynatrace for analysis.  This will demonstrate how to use Dynatrace with OpenTelemetry; without any Dynatrace native components installed on the Kubernetes cluster (Operator, OneAgent, ActiveGate, etc.).</p> <p>Lab tasks:</p> <ol> <li> <p>OpenTelemetry Logs</p> <ul> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for log enrichment</li> <li>Query and visualize logs in Dynatrace using DQL</li> </ul> </li> <li> <p>OpenTelemetry Traces</p> <ul> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for span enrichment</li> <li>Analyze application reliability via traces in Dynatrace</li> </ul> </li> <li> <p>OpenTelemetry Metrics</p> <ul> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Query and visualize metrics in Dynatrace using DQL</li> </ul> </li> <li> <p>OpenTelemetry Capstone</p> <ul> <li>Deploy 2 OpenTelemetry Collectors (DaemonSet + Deployment)</li> <li>Configure OpenTelemetry Collector service pipeline for data enrichment</li> <li>Analyze metrics, traces, and logs in Dynatrace</li> <li>Observe OpenTelemetry Collector health in Dynatrace</li> </ul> </li> </ol>"},{"location":"#technical-specification","title":"Technical Specification","text":""},{"location":"#technologies-used","title":"Technologies Used","text":"<ul> <li>Dynatrace</li> <li>Kubernetes Kind<ul> <li>tested on Kind tag 0.27.0</li> </ul> </li> <li>Cert Manager - *prerequisite for OpenTelemetry Operator<ul> <li>tested on v1.19.1 (October 2025)</li> </ul> </li> <li>OpenTelemetry Operator<ul> <li>tested on v0.136.0 (October 2025)</li> </ul> </li> <li>Dynatrace Distro OpenTelemetry Collector<ul> <li>tested on v0.36.0 (October 2025)</li> </ul> </li> <li>OpenTelemetry AstronomyShop Helm Chart<ul> <li>tested on v0.31.0 (June 2024)</li> </ul> </li> </ul>"},{"location":"#reference-architecture","title":"Reference Architecture","text":"<p>OpenTelemetry Astronomy Shop Demo Architecture</p>"},{"location":"#continue","title":"Continue","text":"<p>In the next section, we'll review the prerequisites for this lab needed before launching our Codespaces instance.</p> <ul> <li>Continue to Getting Started</li> </ul>"},{"location":"2-getting-started/","title":"2. Getting started","text":""},{"location":"2-getting-started/#getting-started","title":"Getting Started","text":"<p>Requirements</p> <ul> <li>A Dynatrace SaaS Tenant with DPS license (sign up here)<ul> <li>Live, Sprint, or Dev environment</li> <li>Full administrator access to the account and tenant</li> </ul> </li> <li>A GitHub account to interact with the demo repository and run a Codespaces instance<ul> <li>Codespaces core-hours and storage available (GitHub Billing &amp; Licensing)</li> </ul> </li> </ul>"},{"location":"2-getting-started/#prerequisites","title":"Prerequisites","text":"<p>You will need full administrator access to a Dynatrace SaaS tenant with a DPS license.</p> <ul> <li>Generate Dynatrace Access Token</li> </ul>"},{"location":"2-getting-started/#generate-dynatrace-access-token","title":"Generate Dynatrace Access Token","text":"<p>Generate a new API access token with the following scopes:</p> <p><pre><code>Ingest events\nIngest logs\nIngest metrics\nIngest OpenTelemetry traces\n</code></pre> See Related Dynatrace API Token Creation Documentation</p> <p></p>"},{"location":"2-getting-started/#continue","title":"Continue","text":"<p>In the next section, we'll launch our Codespaces instance.</p> <ul> <li>Continue to Codespaces</li> </ul>"},{"location":"3-codespaces/","title":"3. Codespaces","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> <li>Real-time observability of Kubernetes clusters using Dynatrace Full-Stack monitoring.</li> <li>Integrated Dynatrace MCP Server to deliver deep, actionable insights across distributed systems.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation </p>"},{"location":"3-codespaces/#create-codespace","title":"Create Codespace","text":"<p>Click to open Codespaces for this lab repository:</p> <p></p> <p>Codespace Configuration</p> <ul> <li>Branch<ul> <li>select the main branch</li> </ul> </li> <li>Dev container configuration<ul> <li>select Dynatrace Enablement Container</li> </ul> </li> <li>Machine type<ul> <li>select 4-core</li> </ul> </li> <li>Region<ul> <li>select any region, preferably one closest to your Dynatrace tenant</li> </ul> </li> </ul>"},{"location":"3-codespaces/#wait-for-codespace","title":"Wait for Codespace","text":"<p>We know your time is very valuable. This codespace takes around 7-10 minutes to be fully operational. A local Kubernetes (kind) cluster will be configured and in it a sample application, Astronomy Shop, will be deployed. To make your experience better, we are also installing and configuring tools like:</p> <p>k9s kubectl helm node jq python3 gh</p>"},{"location":"3-codespaces/#explore-codespace","title":"Explore Codespace","text":"<p>Your Codespace has now deployed the following resources:</p> <ul> <li>A local Kubernetes (kind) cluster, with some pre-deployed apps that will be used later in the demo.</li> </ul> <p>After a couple of minutes, you'll see this screen in your Codespaces terminal. It contains the links to the UI of the application which we will be using for our hands-on training.</p> <p>Sample output: </p>"},{"location":"3-codespaces/#validate-astronomy-shop","title":"Validate Astronomy Shop","text":"<p>When the Codespace instance is idle, validate the <code>astronomy-shop</code> pods are running.</p> <p>Command: <pre><code>kubectl get pods -n astronomy-shop\n</code></pre></p> <p></p>"},{"location":"3-codespaces/#tips-tricks","title":"Tips &amp; Tricks","text":"<p>We want to boost your learning and try to make your experience as smooth as possible with Dynatrace trainings. Your Codespaces have a couple of convenience features added. </p>"},{"location":"3-codespaces/#show-the-greeting","title":"Show the greeting","text":"<p>In the terminal, there are functions loaded for your convenience. By creating a new terminal the greeting will be shown that includes the links to the exposed apps, the Github  pages, the Github Repository, the Dynatrace Tenant that is bound to this devcontainer (if applicable) and some of the tools installed.</p> <p>You can create a new terminal directly in VSCode, type <code>zsh</code> or call the function <code>printGreeting</code> and that will print the greeting with the most relevant information.</p>"},{"location":"3-codespaces/#navigating-in-your-local-kubernetes","title":"Navigating in your local Kubernetes","text":"<p>The client <code>kubectl</code> and <code>k9s</code> are configured so you can navigate in your local Kubernetes.  </p>"},{"location":"3-codespaces/#troubleshooting","title":"Troubleshooting","text":""},{"location":"3-codespaces/#astronomy-shop","title":"Astronomy Shop","text":"<p>If you encounter problems with the Astronomy Shop app deployed in the <code>astronomy-shop</code> namespace, you can easily recycle the pods.</p> <p>Recycle pods: <pre><code>kubectl delete pods --all -n astronomy-shop\n</code></pre></p> <p>But before doing so, if you want to see what is happening we recommend the following: </p> <p>Verify all astronomy-shop pods <pre><code>kubectl get pods -n astronomy-shop\n</code></pre></p> <p>Check for events in the astronomy-shop namespace <pre><code>kubectl get events -n astronomy-shop\n</code></pre></p> <p>Check for system and cluster events  <pre><code>kubectl get events -n kube-system\nkubectl get events -n default\n</code></pre></p>"},{"location":"3-codespaces/#app-exposure","title":"App exposure","text":"<p>The astronomy-shop application is exposed via NodePort and it's mapping port 8080 to Cluster port 30100.</p> <p>Verify service: <pre><code>kubectl get svc astronomy-shop-frontendproxy -n astronomy-shop\n</code></pre></p>"},{"location":"3-codespaces/#problem-patterns","title":"Problem Patterns","text":"<p>The Astronomy Shop demo application provides several feature flags that you can use to simulate different scenarios. These flags are managed by flagd, a simple feature flag service that supports OpenFeature.  However, this release of Astronomy Shop does not include the flagd-ui component, so feature flags must be set by updating the flagd ConfigMap.</p>"},{"location":"3-codespaces/#paymentservicefailure","title":"PaymentServiceFailure","text":"<p>Payment transaction failures that result in the inability for orders to be placed, can be turned on using the <code>paymentServiceFailure</code> feature flag.  There is a helper function to enable the flag and an additional helper function to disable the flag.  Ignore any warnings from <code>kubectl</code> about missing annotations.</p> <p>Enable function: <pre><code>paymentServiceFailureEnable\n</code></pre></p> <p>Disable function: <pre><code>paymentServiceFailureDisable\n</code></pre></p>"},{"location":"3-codespaces/#finish-codespace-setup","title":"Finish Codespace Setup","text":""},{"location":"3-codespaces/#define-workshop-user-variables","title":"Define workshop user variables","text":"<p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre>"},{"location":"3-codespaces/#deploy-opentelemetry-operator","title":"Deploy OpenTelemetry Operator","text":"<p>Move to the base directory</p> <p>Command: <pre><code>cd $REPO_PATH\npwd\n</code></pre> Sample output:</p> <p>/workspaces/enablement-kubernetes-opentelemetry</p> <p>You should find yourself at the base directory of the repository. If not, then navigate to it.</p> <p>Create <code>dynatrace</code> namespace</p> <p>Create the <code>dynatrace</code> namespace.  This is where we'll deploy the OpenTelemetry Collectors.</p> <p>Command: <pre><code>kubectl create namespace dynatrace\n</code></pre></p> <p>Sample output: <pre><code>&gt; namespace/dynatrace created\n</code></pre></p> <p>Create <code>dynatrace-otelcol-dt-api-credentials</code> secret</p> <p>The secret holds the API endpoint and API token that OpenTelemetry data will be sent to.</p> <p>Command: <pre><code>kubectl create secret generic dynatrace-otelcol-dt-api-credentials --from-literal=DT_ENDPOINT=$DT_ENDPOINT --from-literal=DT_API_TOKEN=$DT_API_TOKEN -n dynatrace\n</code></pre> Sample output:</p> <pre><code>&gt; secret/dynatrace-otelcol-dt-api-credentials created\n</code></pre> <p>Deploy <code>cert-manager</code>, pre-requisite for <code>opentelemetry-operator</code></p> <p>Cert-Manager Documentation</p> <p>Command: <pre><code>kubectl apply -f cluster-manifests/cert-manager.yaml\n</code></pre></p> <p>Sample output:</p> <p>namespace/cert-manager created\\ customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\\ customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created</p> <p>Wait 30-60 seconds for cert-manager to finish initializing before continuing.</p> <p>Deploy <code>opentelemetry-operator</code></p> <p>The OpenTelemetry Operator will deploy and manage the custom resource <code>OpenTelemetryCollector</code> deployed on the cluster.</p> <p>Command: <pre><code>kubectl apply -f cluster-manifests/opentelemetry-operator.yaml\n</code></pre></p> <p>Sample output:</p> <p>namespace/opentelemetry-operator-system created\\ customresourcedefinition.apiextensions.k8s.io/instrumentations.opentelemetry.io created\\ customresourcedefinition.apiextensions.k8s.io/opampbridges.opentelemetry.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/opentelemetry-operator-validating-webhook-configuration configured</p> <p>Wait 30-60 seconds for opentelemetry-operator-controller-manager to finish initializing before continuing.</p> <p>Validate that the OpenTelemetry Operator components are running.</p> <p>Command: <pre><code>kubectl get pods -n opentelemetry-operator-system\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE opentelemetry-operator-controller-manager-5d746dbd64-rf9st 2/2 Running 0 1m"},{"location":"3-codespaces/#continue","title":"Continue","text":"<p>In the next section, we'll ship logs from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Logs</li> </ul>"},{"location":"4-opentelemetry-logs/","title":"4. OpenTelemetry Logs","text":""},{"location":"4-opentelemetry-logs/#opentelemetry-logs","title":"OpenTelemetry Logs","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a DaemonSet (Node Agent) to collect pod/container logs from a Kubernetes cluster and ship them to Dynatrace.  Additionally, we'll deploy the OpenTelemetry Collector as a Deployment (Gateway) to watch Kubernetes Events from the Cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for log enrichment</li> <li>Query and visualize logs in Dynatrace using DQL</li> </ol> <p></p> <ul> <li>Learn More</li> </ul>"},{"location":"4-opentelemetry-logs/#prerequisites","title":"Prerequisites","text":"<p>Import Notebook into Dynatrace</p> <p>Notebook</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the logs module directory</p> <p>Command: <pre><code>cd $REPO_PATH/lab-modules/opentelemetry-logs\n</code></pre></p>"},{"location":"4-opentelemetry-logs/#opentelemetry-collector-for-logs","title":"OpenTelemetry Collector for Logs","text":"<p>Dynatrace Documentation</p>"},{"location":"4-opentelemetry-logs/#deploy-opentelemetry-collector","title":"Deploy OpenTelemetry Collector","text":"<p>Dynatrace Distro - Daemonset (Node Agent) Dynatrace Documentation</p> <p>Pod (and container) logs are written to the filesystem of the Node where the pod is running.  Therefore the Collector must be deployed as a Daemonset to read the log files on the local Node.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-logs\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"daemonset\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-8q8tz 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#filelog-receiver","title":"<code>filelog</code> Receiver","text":"<p>OpenTelemetry Documentation</p> <p>The Filelog Receiver tails and parses logs from files. Although it\u2019s not a Kubernetes-specific receiver, it is still the de facto solution for collecting any logs from Kubernetes.  Logs from the Kubernetes Node's filesystem will be read from the Collector running on that Node.  This is why the Collector is deployed as a Daemonset and not a Deployment (or Sidecar).</p> <p>The Filelog Receiver is composed of Operators that are chained together to process a log. Each Operator performs a simple responsibility, such as parsing a timestamp or JSON. Configuring a Filelog Receiver is not trivial.  Refer to the documentation for details.</p> <pre><code>config:\n    receivers:\n      filelog:\n        ...\n    service:\n      pipelines:\n        logs:\n          receivers: [filelog]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(log.file.path)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, k8s.namespace.name, k8s.pod.name, k8s.container.name, content, log.file.path\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>Add Kubernetes Attributes with the <code>k8sattributes</code> Processor</p> <p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p>"},{"location":"4-opentelemetry-logs/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the collector the following permissions via a ClusterRole.</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-logs\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\", \"nodes\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-logs.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-logs created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-logs-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-logs-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-logs\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-logs-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-logs-crb created</p>"},{"location":"4-opentelemetry-logs/#add-k8sattributes-processor","title":"Add <code>k8sattributes</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n    auth_type: \"serviceAccount\"\n    passthrough: false\n        filter:\n        node_from_env_var: KUBE_NODE_NAME\n    extract:\n        metadata:\n            - k8s.namespace.name\n            - k8s.deployment.name\n            - k8s.daemonset.name\n            - k8s.job.name\n            - k8s.cronjob.name\n            - k8s.replicaset.name\n            - k8s.statefulset.name\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.node.name\n            - k8s.container.name\n            - container.id\n            - container.image.name\n            - container.image.tag\n        labels:\n        - tag_name: app.label.component\n            key: app.kubernetes.io/component\n            from: pod\n    pod_association:\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.uid\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.name\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.ip\n        - sources:\n            - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-dns4x 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, k8s.namespace.name, k8s.deployment.name, k8s.pod.name, k8s.container.name, app.label.component, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#resourcedetection-processor","title":"resourcedetection Processor","text":"<p>The resource detection processor can be used to detect resource information from the host, in a format that conforms to the OpenTelemetry resource semantic conventions, and append or override the resource value in telemetry data with this information.  Detectors are available for AWS, Azure, GCP, and several other platforms; see the documentation for more details.</p> <p>This processor is a great plugin for adding attributes such as <code>cloud.account.id</code> and <code>k8s.cluster.name</code> to the telemetry.</p>"},{"location":"4-opentelemetry-logs/#add-resourcedetection-processor","title":"Add <code>resourcedetection</code> Processor","text":"<p>OpenTelemetry Documentation</p> <pre><code>processors:\n  resourcedetection/gcp:\n    detectors: [env, gcp]\n    timeout: 2s\n    override: false\n</code></pre> <p>note: for this lab, the Kind cluster does not have cloud metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: cloud.account.id\n    value: dt-k8s-o11y-account\n    action: insert\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-03.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-fbtk5 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(cloud.account.id) and isNotNull(k8s.cluster.name)\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, cloud.account.id, k8s.cluster.name, k8s.namespace.name, k8s.deployment.name, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#resource-processor","title":"resource Processor","text":""},{"location":"4-opentelemetry-logs/#add-resource-processor","title":"Add <code>resource</code> Processor","text":"<p>OpenTelemetry Documentaiton</p> <p>The <code>resource</code> processor allows us to directly add, remove, or change resource attributes on the telemetry.  View the documentation for more details.</p> <p>We will use this processor to make the follow changes to our telemetry:</p> <ul> <li><code>k8s.pod.ip</code> values in our log data are either the same or invalid; delete the useless attribute</li> <li><code>telemetry.sdk.name</code> set to <code>opentelemetry</code> will allow us to easily identify logs captured through OpenTelemetry</li> <li><code>dynatrace.otel.collector</code> is a non-standardized attribute that we made up to help us identify which Collector captured this data</li> <li><code>dt.security_context</code> is a Dynatrace specific attribute that we use to manage user permissions to the telemetry<ul> <li>This could also be set using OpenPipeline, but this puts control of this attribute's value at the app/infra layer (optionally)</li> </ul> </li> </ul> <p><pre><code>processors:\n    resource:\n        attributes:\n        - key: k8s.pod.ip\n          action: delete\n        - key: telemetry.sdk.name\n          value: opentelemetry\n          action: insert\n        - key: dynatrace.otel.collector\n          value: dynatrace-logs\n          action: insert\n        - key: dt.security_context\n          from_attribute: k8s.cluster.name\n          action: insert\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-04.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre> Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-xx6km 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(dt.security_context)\n| filter isNotNull(cloud.account.id) and isNotNull(k8s.cluster.name)\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, dt.security_context, dynatrace.otel.collector, cloud.account.id, k8s.cluster.name, k8s.namespace.name, k8s.deployment.name, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#otlp-exporter","title":"OTLP Exporter","text":"<p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating logs (traces and metrics too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these logs to be shipped to Dynatrace as well.</p> <p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors. <pre><code>config:\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        logs:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre></p> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-05.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-gu0rm 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#customize-astronomy-shop-helm-values","title":"Customize astronomy-shop helm values","text":"<p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml &gt; astronomy-shop/sed/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command:</p> <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/sed/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> <p>Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(service.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, content, k8s.cluster.name, k8s.pod.name, service.namespace, service.name, telemetry.sdk.language, otel.scope.name\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#opentelemetry-collector-for-events","title":"OpenTelemetry Collector for Events","text":"<p>OpenTelemetry Documentation</p> <p>The Kubernetes Objects receiver collects, either by pulling or watching, objects from the Kubernetes API server. The most common use case for this receiver is watching Kubernetes events, but it can be used to collect any type of Kubernetes object.</p>"},{"location":"4-opentelemetry-logs/#k8sobjects-receiver","title":"<code>k8sobjects</code> Receiver","text":"<p>OpenTelemetry Documentation</p> <p>Our goal is to capture any events related to the <code>astronomy-shop</code> and <code>dynatrace</code> namespaces.</p> <pre><code>receivers:\n  k8sobjects/events:\n    auth_type: serviceAccount\n    objects:\n      - name: events\n        mode: watch\n        namespaces: [astronomy-shop,dynatrace]\n</code></pre>"},{"location":"4-opentelemetry-logs/#configure-kubernetes-rbac_1","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes events</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. Since service accounts are the only authentication option you must give the service account the proper access. For any object you want to collect you need to ensure the name is added to the cluster role. </p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-events\nrules:\n- apiGroups: [\"\"]\n  resources: [\"events\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-events.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-events created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-events-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-events-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-events\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-events-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-events-crb created</p> <p>Add <code>k8sobjects</code> receiver to collect Kubernetes events as logs</p> <p>OpenTelemetry Documentation</p> <pre><code>receivers:\n  k8sobjects/events:\n    auth_type: serviceAccount\n    objects:\n      - name: events\n        mode: watch\n        namespaces: [astronomy-shop,dynatrace]\n</code></pre> <p>Since the receiver gathers telemetry for the cluster as a whole, only one instance of the receiver is needed across the cluster in order to collect all the data.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-events\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/events/otel-collector-events-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-events created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-events-collector-559d5b9d77-rb26d 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#generate-events","title":"Generate Events","text":"<p>Generate events using deployment scale command</p> <p>Kubernetes Documentation</p> <p>We can generate new Kubernetes events related to the <code>astronomy-shop</code> namespace by scaling a deployment up and then scaling it back down.</p> <p>Command: <pre><code>kubectl scale deployment astronomy-shop-imageprovider -n astronomy-shop --replicas=2\n</code></pre> Sample output:</p> <p>deployment.apps/astronomy-shop-imageprovider scaled</p> <p>Command: <pre><code>kubectl scale deployment astronomy-shop-imageprovider -n astronomy-shop --replicas=1\n</code></pre> Sample output:</p> <p>deployment.apps/astronomy-shop-imageprovider scaled</p> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter dynatrace.otel.collector == \"dynatrace-events\" and event.domain == \"k8s\" and k8s.resource.name == \"events\"\n| filter object.metadata.namespace == \"astronomy-shop\"\n| sort timestamp desc\n| limit 100\n| fields timestamp, k8s.cluster.name, {object.metadata.namespace, alias: k8s.namespace.name}, object.message, object.reason, event.name\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#wrap-up","title":"Wrap Up","text":""},{"location":"4-opentelemetry-logs/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect logs, enrich log attributes for better context, and ship those logs to Dynatrace for analysis.</p> <ul> <li>The OpenTelemetry Collector was deployed as a DaemonSet, behaving as an Agent running on each Node</li> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship logs to Dynatrace<ul> <li>The <code>filelog</code> receiver scrapes logs from the Node filesystem and parses the contents</li> <li>The <code>otlp</code> receiver receives logs that are exported from agents, SDKs, and other Collectors</li> <li>The <code>k8sattributes</code> processor enriches the logs with Kubernetes attributes</li> <li>The <code>resourcedetection</code> processor enriches the logs with cloud and cluster attributes</li> <li>The <code>resource</code> processor enriches the logs with custom (resource) attributes</li> <li>The <code>k8sobjects</code> receiver watches for Kubernetes events (and other resources) on the cluster</li> </ul> </li> <li>Dynatrace DQL (via Notebooks) allows you to perform powerful queries and analysis of the log data</li> </ul>"},{"location":"4-opentelemetry-logs/#continue","title":"Continue","text":"<p>In the next section, we'll ship traces and spans from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Traces</li> </ul>"},{"location":"5-opentelemetry-traces/","title":"5. OpenTelemetry Traces","text":""},{"location":"5-opentelemetry-traces/#opentelemetry-traces","title":"OpenTelemetry Traces","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a Deployment (Gateway) to collect application traces/spans, generated by OpenTelemetry, from a Kubernetes cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for span enrichment</li> <li>Analyze application reliability via traces in Dynatrace</li> </ol> <p> </p> <ul> <li>Learn More</li> </ul>"},{"location":"5-opentelemetry-traces/#prerequisites","title":"Prerequisites","text":"<p>Import Notebook into Dynatrace</p> <p>Notebook</p> <p>Import Dashboard into Dynatrace</p> <p>Dashboard</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the traces module directory</p> <p>Command: <pre><code>cd $REPO_PATH/lab-modules/opentelemetry-traces\n</code></pre></p>"},{"location":"5-opentelemetry-traces/#opentelemetry-collector-for-traces","title":"OpenTelemetry Collector for Traces","text":"<p>Dynatrace Documentation</p> <p>Distributed traces and their spans, generated by OpenTelemetry agents and SDKs, are exported from their origin to an <code>otlp</code> receiver.  These traces/spans can be sent directly to Dynatrace, using the OTLP ingest API.  However, it is highly recommended to use the OpenTelemetry Collector to process, filter, and manipulate the data first.</p>"},{"location":"5-opentelemetry-traces/#otlp-receiver","title":"<code>otlp</code> Receiver","text":"<p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors.</p> <pre><code>config:\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre>"},{"location":"5-opentelemetry-traces/#deploy-opentelemetry-collector-deployment","title":"Deploy OpenTelemetry Collector Deployment","text":"<p>Dynatrace Documentation</p> <p>The gateway collector deployment pattern consists of applications (or other collectors) sending telemetry signals to a single OTLP endpoint provided by one or more collector instances running as a standalone service (for example, a deployment in Kubernetes), typically per cluster, per data center or per region.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-traces\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-ms24p 1/1 Running 0 1m <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Dynatrace Distro</p> <p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating traces (logs and metrics too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these traces to be shipped to Dynatrace as well.</p> <p>Customize astronomy-shop helm values</p> <p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml &gt; astronomy-shop/sed/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/sed/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p>"},{"location":"5-opentelemetry-traces/#analyze-opentelemetry-traces-in-dynatrace","title":"Analyze OpenTelemetry Traces in Dynatrace","text":"<p>Open the opentelemetry-traces_dt_notebook Notebook.</p> <p>Query spans in Dynatrace</p> <p>DQL:</p> <pre><code>fetch spans\n| filter isNotNull(service.name) and isNotNull(service.namespace) and isNotNull(otel.scope.name)\n| sort start_time desc\n| limit 100\n| fields start_time, end_time, service.name, service.namespace, trace.id, span.id, duration\n</code></pre> <p>Result:</p> <p></p>"},{"location":"5-opentelemetry-traces/#paymentservice-spans","title":"PaymentService Spans","text":"<p>Now that you've confirmed OpenTelemetry spans are successfully ingested into Dynatrace, it's time to narrow your focus to a specific business-critical function: payment processing. In this next step, you'll refine your DQL query to isolate traces and spans related to the <code>paymentservice</code> workload and the <code>charge</code> operation. This targeted analysis allows you to observe how Dynatrace captures and contextualizes telemetry data for a key service, helping you validate instrumentation, understand service behavior, and identify potential performance bottlenecks in the payment flow.</p> <p>Query spans in Dynatrace</p> <p>DQL:</p> <pre><code>fetch spans\n| filter isNotNull(service.name) and isNotNull(service.namespace) and isNotNull(otel.scope.name)\n| filter matchesValue(service.name,\"paymentservice\") and matchesValue(endpoint.name,\"oteldemo.PaymentService.Charge\")\n| sort start_time desc\n| limit 10\n| fields start_time, end_time, service.name, service.namespace, trace.id, span.id, duration, app.payment.amount\n</code></pre> <p>Result:</p> <p></p> <p>With a filtered view of spans related to the <code>paymentservice</code> and its <code>charge</code> operation, you're now ready to dive deeper into the behavior of individual traces. Next, you'll select one of the trace IDs from your query results and open it in the Distributed Tracing App. This will allow you to explore the full trace waterfall, visualize the end-to-end flow of the payment processing transaction, and analyze how the Charge span fits into the broader service interaction. This hands-on inspection is key to understanding latency contributors, service dependencies, and the overall health of your instrumented application.</p> <p> </p> <p>Take some time to analyze the distributed trace containing the <code>paymentservice</code> span.  Review the captured metadata, detailed timings, logs, exceptions, and topology context.</p> <p>Refer to the Dynatrace documentation for more details</p> <p></p> <p>These attributes are good, but we can add more to provide better Kubernetes context to these transactions.</p>"},{"location":"5-opentelemetry-traces/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>Add Kubernetes Attributes with the <code>k8sattributes</code> Processor</p> <p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p>"},{"location":"5-opentelemetry-traces/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the collector the following permissions via a ClusterRole.</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-traces\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\", \"nodes\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-traces.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-traces created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-traces-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-traces-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-traces\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-traces-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-traces-crb created</p>"},{"location":"5-opentelemetry-traces/#add-k8sattributes-processor","title":"Add <code>k8sattributes</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n    auth_type: \"serviceAccount\"\n    passthrough: false\n        filter:\n        node_from_env_var: KUBE_NODE_NAME\n    extract:\n        metadata:\n            - k8s.namespace.name\n            - k8s.deployment.name\n            - k8s.daemonset.name\n            - k8s.job.name\n            - k8s.cronjob.name\n            - k8s.replicaset.name\n            - k8s.statefulset.name\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.node.name\n            - k8s.container.name\n            - container.id\n            - container.image.name\n            - container.image.tag\n        labels:\n        - tag_name: app.label.component\n            key: app.kubernetes.io/component\n            from: pod\n    pod_association:\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.uid\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.name\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.ip\n        - sources:\n            - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-xn84p 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Kubernetes Attributes</p> <p>DQL:</p> <pre><code>fetch spans\n| filter isNotNull(service.name) and isNotNull(service.namespace) and isNotNull(otel.scope.name)\n| filter matchesValue(service.name,\"paymentservice\") and matchesValue(endpoint.name,\"oteldemo.PaymentService.Charge\")\n| filter isNotNull(app.label.component)\n| sort start_time desc\n| limit 10\n| fields start_time, end_time, service.name, service.namespace, trace.id, span.id, duration, app.payment.amount, app.label.component\n</code></pre> <p>Result:</p> <p></p> <p>The spans are enriched with the additional Kubernetes metadata, including the attribute <code>app.label.component</code> which is obtained from the Kubernetes pod label <code>app.kubernetes.io/component</code>.</p> <p>Analyze a distributed trace and review the additional metadata.</p> <p></p>"},{"location":"5-opentelemetry-traces/#resourcedetection-processor","title":"resourcedetection Processor","text":""},{"location":"5-opentelemetry-traces/#add-resourcedetection-processor","title":"Add <code>resourcedetection</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The resource detection processor can be used to detect resource information from the host, in a format that conforms to the OpenTelemetry resource semantic conventions, and append or override the resource value in telemetry data with this information.  Detectors are available for AWS, Azure, GCP, and several other platforms; see the documentation for more details.</p> <pre><code>processors:\n  resourcedetection/gcp:\n    detectors: [env, gcp]\n    timeout: 2s\n    override: false\n</code></pre> <p>note: for this lab, the Kind cluster does not have cloud metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: cloud.account.id\n    value: dt-k8s-o11y-account\n    action: insert\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-03.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-rp21d 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Cloud Attributes</p> <p>DQL:</p> <pre><code>fetch spans\n| filter isNotNull(service.name) and isNotNull(service.namespace) and isNotNull(otel.scope.name)\n| filter matchesValue(service.name,\"paymentservice\") and matchesValue(endpoint.name,\"oteldemo.PaymentService.Charge\")\n| filter isNotNull(app.label.component) and isNotNull(cloud.account.id)\n| sort start_time desc\n| limit 10\n| fields start_time, end_time, service.name, service.namespace, trace.id, span.id, duration, app.payment.amount, app.label.component, cloud.account.id, k8s.cluster.name\n</code></pre> <p>Result:</p> <p></p> <p>The spans now have the additional metadata, <code>cloud.account.id</code> and <code>k8s.cluster.name</code>.</p> <p>Analyze a distributed trace and review the additional metadata.</p> <p></p>"},{"location":"5-opentelemetry-traces/#resource-processor","title":"resource Processor","text":""},{"location":"5-opentelemetry-traces/#add-resource-processor","title":"Add <code>resource</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>resource</code> processor allows us to directly add, remove, or change resource attributes on the telemetry.  View the documentation for more details.</p> <p>We will use this processor to make the follow changes to our telemetry:</p> <ul> <li><code>k8s.pod.ip</code> values in our data are either the same or invalid; delete the useless attribute</li> <li><code>telemetry.sdk.name</code> set to <code>opentelemetry</code> will allow us to easily identify data captured through OpenTelemetry</li> <li><code>dynatrace.otel.collector</code> is a non-standardized attribute that we made up to help us identify which Collector captured this data</li> <li><code>dt.security_context</code> is a Dynatrace specific attribute that we use to manage user permissions to the telemetry<ul> <li>This could also be set using OpenPipeline, but this puts control of this attribute's value at the app/infra layer (optionally)</li> </ul> </li> </ul> <p><pre><code>processors:\n    resource:\n        attributes:\n        - key: k8s.pod.ip\n          action: delete\n        - key: telemetry.sdk.name\n          value: opentelemetry\n          action: insert\n        - key: dynatrace.otel.collector\n          value: dynatrace-traces\n          action: insert\n        - key: dt.security_context\n          from_attribute: k8s.cluster.name\n          action: insert\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-04.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-ny98q 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Custom Resource Attributes</p> <p>DQL:</p> <pre><code>fetch spans\n| filter isNotNull(service.name) and isNotNull(service.namespace) and isNotNull(otel.scope.name)\n| filter matchesValue(service.name,\"paymentservice\") and matchesValue(endpoint.name,\"oteldemo.PaymentService.Charge\")\n| filter isNotNull(app.label.component) and isNotNull(cloud.account.id) and isNotNull(dynatrace.otel.collector)\n| sort start_time desc\n| limit 10\n| fields start_time, end_time, service.name, service.namespace, trace.id, span.id, duration, app.payment.amount, app.label.component, cloud.account.id, k8s.cluster.name, dynatrace.otel.collector\n</code></pre> <p>Result:</p> <p></p> <p>The spans now have the additional metadata, including <code>dynatrace.otel.collector</code>.</p> <p>Analyze a distributed trace and review the additional metadata.</p> <p></p>"},{"location":"5-opentelemetry-traces/#dynatrace-dashboard-with-unified-services-from-opentelemetry","title":"Dynatrace Dashboard with Unified Services from OpenTelemetry","text":"<p>Open the Dashboard that you imported to view the throughput, response time, and failure metrics for the <code>astronomy-shop</code> application services.</p> <p></p>"},{"location":"5-opentelemetry-traces/#distributed-tracing-app","title":"Distributed Tracing App","text":"<p>The Distributed Tracing App provides a powerful interface for analyzing end-to-end traces across your services. Once you've identified a trace of interest\u2014such as one containing the <code>PaymentService.Charge</code> span, you can use the app to drill into its full execution path.</p> <p>The app offers multiple ways to locate relevant traces quickly:</p> <ul> <li>Filter bar: Use this to apply precise filters such as <code>service.name</code>, <code>span.kind</code>, or custom attributes like <code>app.payment.amount</code>.</li> <li>Segments: These predefined filters help you zero in on common trace patterns or service-specific activity.</li> <li>Facets: Dynamically generated from your trace data, facets allow you to pivot your search based on attributes like HTTP status codes, error flags, or user-defined tags.</li> </ul> <p></p> <p>Once you've applied your filters, the trace list updates in real time. From there, you can select a trace to view its waterfall visualization, which shows the sequence and timing of spans across services. This makes it easy to identify latency contributors, understand service interactions, and validate that your OpenTelemetry instrumentation is capturing the right context.</p> <p></p>"},{"location":"5-opentelemetry-traces/#wrap-up","title":"Wrap Up","text":""},{"location":"5-opentelemetry-traces/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect traces, enrich span attributes for better context, and ship those traces/spans to Dynatrace for analysis.</p> <ul> <li>The OpenTelemetry Collector was deployed as a Deployment, behaving as a Gateway on the cluster</li> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship traces to Dynatrace<ul> <li>The <code>otlp</code> receiver receives traces (and other signals) from OpenTelemetry exporters via gRPC/HTTP</li> <li>The <code>k8sattributes</code> processor enriches the spans with Kubernetes attributes</li> <li>The <code>resourcedetection</code> processor enriches the spans with cloud and cluster (GCP/GKE) attributes</li> <li>The <code>resource</code> processor enriches the spans with custom (resource) attributes</li> </ul> </li> <li>Dynatrace allows you to perform powerful queries and analysis of the trace/span data</li> </ul>"},{"location":"5-opentelemetry-traces/#continue","title":"Continue","text":"<p>In the next section, we'll ship metrics and datapoints from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Metrics</li> </ul>"},{"location":"6-opentelemetry-metrics/","title":"6. OpenTelemetry Metrics","text":""},{"location":"6-opentelemetry-metrics/#opentelemetry-metrics","title":"OpenTelemetry Metrics","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a DaemonSet (Node Agent) to collect Node (kubelet) metrics from a Kubernetes cluster and ship them to Dynatrace.  Additionally, we'll utilize a second OpenTelemetry Collector deployed as a Deployment (Gateway) to collect Cluster (Kubernetes API) metrics from the Kubernetes cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Query and visualize metrics in Dynatrace using DQL</li> </ol> <ul> <li>Learn More</li> </ul>"},{"location":"6-opentelemetry-metrics/#prerequisites","title":"Prerequisites","text":"<p>Import Notebook into Dynatrace</p> <p>Notebook</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the metrics module directory</p> <p>Command: <pre><code>cd $REPO_PATH/lab-modules/opentelemetry-metrics\n</code></pre></p>"},{"location":"6-opentelemetry-metrics/#collector-for-node-metrics","title":"Collector for Node Metrics","text":"<p>Kubernetes Node Metrics</p> <p>Each Kubernetes Node runs a kubelet that includes an API server. The <code>kubeletstats</code> Receiver connects to that kubelet via the API server to collect metrics about the node and the workloads running on the node.</p>"},{"location":"6-opentelemetry-metrics/#deploy-opentelemetry-collector","title":"Deploy OpenTelemetry Collector","text":"<p>Dynatrace Distro - Daemonset (Node Agent)</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-metrics-node\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  env:\n    - name: K8S_NODE_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n  mode: \"daemonset\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-node-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-node created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-node-collector-2kzlp 1/1 Running 0 1m"},{"location":"6-opentelemetry-metrics/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the receiver uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the Collector the following permissions via a ClusterRole.</p> <pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-metrics\nrules:\n  - apiGroups: ['']\n    resources: ['events', 'namespaces', 'namespaces/status', 'nodes', 'nodes/spec', 'nodes/stats', 'nodes/proxy', 'pods', 'pods/status', 'replicationcontrollers', 'replicationcontrollers/status', 'resourcequotas', 'services']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['apps']\n    resources: ['daemonsets', 'deployments', 'replicasets', 'statefulsets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['extensions']\n    resources: ['daemonsets', 'deployments', 'replicasets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['batch']\n    resources: ['jobs', 'cronjobs']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['autoscaling']\n    resources: ['horizontalpodautoscalers']\n    verbs: ['get', 'list', 'watch']\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-metrics.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-metrics created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-metrics-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-metrics-node-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-metrics\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-metrics-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-metrics-crb created</p>"},{"location":"6-opentelemetry-metrics/#kubeletstats-receiver","title":"<code>kubeletstats</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p>By default, metrics will be collected for pods and nodes, but you can configure the receiver to collect container and volume metrics as well. The receiver also allows configuring how often the metrics are collected:</p> <pre><code>config:\n    receivers:\n      kubeletstats:\n        collection_interval: 30s\n        auth_type: 'serviceAccount'\n        endpoint: '${env:K8S_NODE_NAME}:10250'\n        insecure_skip_verify: true\n        metric_groups:\n          - node\n          - pod\n          - container\n</code></pre> <p>Default Metrics: OpenTelemetry Documentation</p> <p>note: for this lab, the Kind cluster does not have cluster metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Query Node metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries node_cpu = avg(k8s.node.cpu.usage), by: {k8s.cluster.name, k8s.node.name}\n</code></pre> Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p> <p>Add <code>k8sattributes</code> processor</p> <p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n  auth_type: \"serviceAccount\"\n  passthrough: false\n  filter:\n    node_from_env_var: KUBE_NODE_NAME\n  extract:\n    metadata:\n      - k8s.namespace.name\n      - k8s.deployment.name\n      - k8s.daemonset.name\n      - k8s.job.name\n      - k8s.cronjob.name\n      - k8s.replicaset.name\n      - k8s.statefulset.name\n      - k8s.pod.name\n      - k8s.pod.uid\n      - k8s.node.name\n      - k8s.container.name\n      - container.id\n      - container.image.name\n      - container.image.tag\n    labels:\n      - tag_name: app.label.component\n        key: app.kubernetes.io/component\n        from: pod\n    pod_association:\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.uid\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.name\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.ip\n      - sources:\n          - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-node-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-node configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-node-collector-drk1p 1/1 Running 0 1m <p>Query Pod metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries pod_cpu = avg(k8s.pod.cpu.usage), by: { k8s.pod.name, k8s.node.name, k8s.namespace.name, k8s.deployment.name, k8s.cluster.name, k8s.pod.uid }\n| filter k8s.namespace.name == \"astronomy-shop\" and k8s.deployment.name == \"astronomy-shop-productcatalogservice\"\n</code></pre></p> <p>Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#collector-for-cluster-metrics","title":"Collector for Cluster Metrics","text":"<p>The Kubernetes Cluster Receiver collects metrics and entity events about the cluster as a whole using the Kubernetes API server. Use this receiver to answer questions about pod phases, node conditions, and other cluster-wide questions.</p>"},{"location":"6-opentelemetry-metrics/#deploy-opentelemetry-collector_1","title":"Deploy OpenTelemetry Collector","text":"<p>Dynatrace Distro - Deployment (Gateway)</p> <p>OpenTelemetry Documentation</p> <p>Since the receiver gathers telemetry for the cluster as a whole, only one instance of the receiver is needed across the cluster in order to collect all the data.  The Collector will be deployed as a Deployment (Gateway).</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-metrics-cluster\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-cluster-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-cluster created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-cluster-collector-7bd8dc4995-6sgs2 1/1 Running 0 1m"},{"location":"6-opentelemetry-metrics/#k8s_cluster-receiver","title":"<code>k8s_cluster</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p><pre><code>config:\n    receivers:\n      k8s_cluster:\n        collection_interval: 60s\n        node_conditions_to_report: [ \"Ready\", \"MemoryPressure\", \"DiskPressure\" ]\n        allocatable_types_to_report: [ \"cpu\",\"memory\" ]\n        metadata_collection_interval: 5m\n</code></pre> Default Metrics: OpenTelemetry Documentation</p> <p>Query Deployment metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries pods_avail = min(k8s.deployment.available), by: {k8s.cluster.name, k8s.deployment.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#export-application-metrics","title":"Export Application Metrics","text":"<p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating metrics (traces and logs too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these metrics to be shipped to Dynatrace as well.</p>"},{"location":"6-opentelemetry-metrics/#otlp-receiver","title":"<code>otlp</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors.</p> <pre><code>config:\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        metrics:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Dynatrace Distro</p> <p>Customize astronomy-shop helm values</p> <p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml &gt; astronomy-shop/sed/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/sed/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p> <p>Query <code>astronomy-shop</code> metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries jvm_mem_used = avg(jvm.memory.used), by: {service.name, k8s.cluster.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p> <p>DQL: <pre><code>timeseries avg(kafka.consumer.request_rate), by: {service.name, k8s.cluster.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p> <p>Browse available metrics in Dynatrace</p> <p>You can browse all available metrics from OpenTelemetry sources in the Metrics Browser.  Filter on <code>Dimension:otel.scope.name</code> to find relevant metrics.</p> <p>Dynatrace Documentation</p> <p></p>"},{"location":"6-opentelemetry-metrics/#wrap-up","title":"Wrap Up","text":""},{"location":"6-opentelemetry-metrics/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect metrics, enrich metric attributes for better context, and ship those metrics to Dynatrace for analysis.</p> <ul> <li>One Dynatrace Distro OpenTelemetry Collector was deployed as a DaemonSet, behaving as an Agent running on each Node<ul> <li>The <code>kubeletstats</code> receiver scrapes metrics from the local kubelet on the Node</li> <li>The <code>k8sattributes</code> processor enriches the metrics with Kubernetes attributes that may be missing without it</li> </ul> </li> <li>A second Dynatrace Distro OpenTelemetry Collector was deployed as a Deployment, behaving as a Gateway<ul> <li>The <code>k8s_cluster</code> receiver queries the Kubernetes cluster API to retrieve metrics</li> <li>The <code>k8sattributes</code> processor enriches the metrics with Kubernetes attributes that may be missing without it</li> <li>The <code>otlp</code> receiver receives signals that are exported from agents, SDKs, and other Collectors</li> </ul> </li> <li>Metrics produced by the OpenTelemetry SDKs and Agents are exported to the <code>otlp</code> receiver</li> <li>Dynatrace DQL (via Notebooks) allows you to perform powerful queries and analysis of the metric data</li> </ul>"},{"location":"6-opentelemetry-metrics/#continue","title":"Continue","text":"<p>In the next section, we'll integrate and apply what we have learned in the OpenTelemetry Capstone.</p> <ul> <li>Continue to OpenTelemetry Capstone</li> </ul>"},{"location":"7-opentelemetry-capstone/","title":"7. OpenTelemetry Capstone","text":""},{"location":"7-opentelemetry-capstone/#opentelemetry-capstone","title":"OpenTelemetry Capstone","text":"<p>Capstone Module</p> <p>What is a Capstone? A hands-on, culminating learning experience where participants apply the knowledge and skills they've gained throughout a course or program to solve a real-world problem, create a project, or present a comprehensive solution.</p> <p>In this lab module we'll utilize multiple OpenTelemetry Collectors to collect application traces/spans, log records, and metric data points generated by OpenTelemetry, from a Kubernetes cluster and ship them to Dynatrace.  This is a capstone lab that utilizes the concepts of the previous Kubernetes OpenTelemetry lab modules.</p> <p>Lab tasks:</p> <ol> <li>Deploy 2 OpenTelemetry Collectors</li> <li>Configure OpenTelemetry Collector service pipeline for data enrichment</li> <li>Analyze metrics, traces, and logs in Dynatrace</li> <li>Observe OpenTelemetry Collector health in Dynatrace</li> </ol> <ul> <li>Learn More</li> </ul>"},{"location":"7-opentelemetry-capstone/#prerequisites","title":"Prerequisites","text":"<p>Import Dashboard into Dynatrace</p> <p> astronomy-shop dashboard</p> <p>Add OpenTelemetry Dashboards from Hub</p> <p>Locate the OpenTelemetry Dashboards App in the Hub.  Install the App to have OpenTelemetry Collector self-monitoring and Kubernetes monitoring dashboards added to your environment.</p> <p></p> <p>Define workshop user variables In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the capstone module directory</p> <p>Command: <pre><code>cd $REPO_PATH/lab-modules/opentelemetry-capstone\n</code></pre></p> <p>Clean Up Previous Deployments</p> <p>Delete <code>dynatrace</code> namespace and all previous deployments</p> <p>Command: <pre><code>kubectl delete ns dynatrace\n</code></pre></p>"},{"location":"7-opentelemetry-capstone/#opentelemetry-operator-and-role-based-access","title":"OpenTelemetry Operator and Role Based Access","text":"<p>Deploy OpenTelemetry Operator</p> <p>Create <code>dynatrace</code> namespace</p> <p>Command: <pre><code>kubectl create namespace dynatrace\n</code></pre> Sample output:</p> <p>namespace/dynatrace created</p> <p>Create <code>dynatrace-otelcol-dt-api-credentials</code> secret</p> <p>The secret holds the API endpoint and API token that OpenTelemetry data will be sent to.</p> <p>Command: <pre><code>kubectl create secret generic dynatrace-otelcol-dt-api-credentials --from-literal=DT_ENDPOINT=$DT_ENDPOINT --from-literal=DT_API_TOKEN=$DT_API_TOKEN -n dynatrace\n</code></pre> Sample output:</p> <p>secret/dynatrace-otelcol-dt-api-credentials created</p> <p>Deploy <code>cert-manager</code>, pre-requisite for <code>opentelemetry-operator</code></p> <p>Cert Manager Documentation</p> <p>Command: <pre><code>kubectl apply -f opentelemetry/cert-manager.yaml\n</code></pre> Sample output:</p> <p>namespace/cert-manager created\\ customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\\ customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created</p> <p>Wait 30-60 seconds for cert-manager to finish initializing before continuing.</p> <p>Deploy <code>opentelemetry-operator</code></p> <p>The OpenTelemetry Operator will deploy and manage the custom resource <code>OpenTelemetryCollector</code> deployed on the cluster.</p> <p>Command: <pre><code>kubectl apply -f opentelemetry/opentelemetry-operator.yaml\n</code></pre> Sample output:</p> <p>namespace/opentelemetry-operator-system created\\ customresourcedefinition.apiextensions.k8s.io/instrumentations.opentelemetry.io created\\ customresourcedefinition.apiextensions.k8s.io/opampbridges.opentelemetry.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/opentelemetry-operator-validating-webhook-configuration configured</p> <p>Wait 30-60 seconds for opentelemetry-operator-controller-manager to finish initializing before continuing.</p> <p>Validate that the OpenTelemetry Operator components are running.</p> <p>Command: <pre><code>kubectl get pods -n opentelemetry-operator-system\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE opentelemetry-operator-controller-manager-5d746dbd64-rf9st 2/2 Running 0 1m <p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole\nrules:\n  - apiGroups: ['']\n    resources: ['events', 'namespaces', 'namespaces/status', 'nodes', 'nodes/spec', 'nodes/stats', 'nodes/proxy', 'pods', 'pods/status', 'replicationcontrollers', 'replicationcontrollers/status', 'resourcequotas', 'services']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['apps']\n    resources: ['daemonsets', 'deployments', 'replicasets', 'statefulsets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['extensions']\n    resources: ['daemonsets', 'deployments', 'replicasets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['batch']\n    resources: ['jobs', 'cronjobs']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['autoscaling']\n    resources: ['horizontalpodautoscalers']\n    verbs: ['get', 'list', 'watch']\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service accounts</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-deployment-collector\n  namespace: dynatrace\n- kind: ServiceAccount\n  name: dynatrace-daemonset-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-crb created</p>"},{"location":"7-opentelemetry-capstone/#dynatrace-deployment-collector","title":"Dynatrace Deployment Collector","text":"<p>OpenTelemetry Collector - Dynatrace Distro (Deployment)</p> <p>Dynatrace Documentation</p> <p>Receivers: <code>otlp</code>, <code>prometheus</code>, <code>k8s_cluster</code>, <code>k8sobjects</code></p> MODULE DT DEPLOY DT DAEMON otlp - [x] - [ ] prometheus - [x] - [x] filelog - [ ] - [x] kubeletstats - [ ] - [x] k8s_cluster - [x] - [ ] k8sobjects - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p>Dynatrace Documentation <pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-deployment\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/dynatrace/otel-collector-dynatrace-deployment-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-deployment created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-deployment-collector-796546fbd6-kqflf 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#dynatrace-daemonset-collector","title":"Dynatrace Daemonset Collector","text":"<p>OpenTelemetry Collector - Dynatrace Distro (Daemonset)</p> <p>Dynatrace Documentation</p> <p>Receivers: <code>filelog</code>, <code>prometheus</code>, <code>kubeletstats</code></p> MODULE DT DEPLOY DT DAEMON otlp - [x] - [ ] prometheus - [x] - [x] filelog - [ ] - [x] kubeletstats - [ ] - [x] k8s_cluster - [x] - [ ] k8sobjects - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p>Dynatrace Documentation</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1beta1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-daemonset\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"daemonset\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/dynatrace/otel-collector-dynatrace-daemonset-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-daemonset created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-daemonset-collector-h69pz 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#configure-astronomy-shop-otlp-export","title":"Configure Astronomy Shop OTLP Export","text":"<pre><code>config:\n    receivers:\n      otlp:\n        protocols:\n          http:\n            # Since this collector needs to receive data from the web, enable cors for all origins\n            # `allowed_origins` can be refined for your deployment domain\n            cors:\n              allowed_origins:\n                - \"http://*\"\n                - \"https://*\"\n      httpcheck/frontendproxy:\n        targets:\n          - endpoint: 'http://{{ include \"otel-demo.name\" . }}-frontendproxy:8080'\n\n    exporters:\n      # Dynatrace OTel Collector\n      otlphttp/dynatrace:\n        endpoint: http://dynatrace-deployment-collector.dynatrace.svc.cluster.local:4318\n\n    processors:\n      resource:\n        attributes:\n        - key: service.instance.id\n          from_attribute: k8s.pod.uid\n          action: insert\n\n    connectors:\n      spanmetrics: {}\n\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [memory_limiter, resource, batch]\n          exporters: [spanmetrics, otlphttp/dynatrace]\n        metrics:\n          receivers: [httpcheck/frontendproxy, otlp, spanmetrics]\n          processors: [memory_limiter, resource, batch]\n          exporters: [otlphttp/dynatrace]\n        logs:\n          processors: [memory_limiter, resource, batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Dynatrace Distro (Deployment)</p> <p>Customize astronomy-shop helm values</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml &gt; astronomy-shop/sed/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/sed/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p>"},{"location":"7-opentelemetry-capstone/#validate-and-analyze-data-in-dynatrace","title":"Validate and Analyze Data in Dynatrace","text":"<p>Analyze metrics, traces, and logs in Dynatrace dashboard</p> <p> astronomy-shop dashboard</p>"},{"location":"7-opentelemetry-capstone/#opentelemetry-collector-health","title":"OpenTelemetry Collector Health","text":""},{"location":"7-opentelemetry-capstone/#observe-opentelemetry-collector-health-in-dynatrace","title":"Observe OpenTelemetry Collector health in Dynatrace","text":"<p>OpenTelemetry Documentation</p> <ul> <li>Add <code>dynatrace.otel.collector</code> to Dynatrace's metric attribute allow list</li> <li>Enable OpenTelemetry Collector health metrics (Prometheus)</li> <li>Modify OpenTelemetry Collector health metrics for Dynatrace support</li> <li>View OpenTelemetry Collector health metrics in Dynatrace</li> </ul> <p>Add <code>dynatrace.otel.collector</code> to Dynatrace's metric attribute allow list</p> <p>By default, the metric attribute <code>dynatrace.otel.collector</code> is dropped by Dynatrace.  Add it to the allow list in your Dynatrace tenant:</p> <p>Dynatrace Documentation </p> <p>Enable OpenTelemetry Collector self-monitoring telemetry</p> <p>Add telemetry service to Collector config: <pre><code>service:\n      telemetry:\n        logs:\n          level: \"info\"\n          encoding: \"json\"\n        metrics:\n          level: \"normal\"\n          # set up OTLP exporter to self OTLP receiver\n          readers:\n            - periodic:\n                interval: 10000\n                timeout: 5000\n                exporter:\n                  otlp:\n                    protocol: http/protobuf\n                    temporality_preference: delta\n                    endpoint: \"http://${env:MY_POD_IP}:4318/v1/metrics\"\n</code></pre></p> <p>For more details and the latest information, see the Dynatrace Documentation for Collector self-monitoring.</p> <p>View OpenTelemetry Collector self-mon health metrics in Dynatrace</p> <p>OpenTelemetry Collector self-mon metrics have the <code>otelcol_</code> prefix and can be found in the Dynatrace metric browser: </p> <p>You can also query the metric series (metric key + dimensions) using DQL: <pre><code>fetch metric.series\n| filter startsWith(metric.key,\"otelcol\")\n</code></pre></p> <p>Use the read-made dashboards from OpenTelemetry Dashboards to view and analyze the OpenTelemetry Collector health.</p> <p></p>"},{"location":"7-opentelemetry-capstone/#wrap-up","title":"Wrap Up","text":""},{"location":"7-opentelemetry-capstone/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect metrics, traces, and logs from Kubernetes and ship them to Dynatrace for analysis.</p> <ul> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship telemetry to Dynatrace<ul> <li>The <code>otlp</code> receiver receives metrics, traces, and logs from OpenTelemetry exporters via gRPC/HTTP</li> <li>The <code>filelog</code> receiver scrapes logs from the Node filesystem and parses the contents</li> <li>The <code>prometheus</code> receiver scrapes metric data exposed by Pod Prometheus endpoints</li> <li>The <code>kubeletstats</code> receiver scrapes metrics from the local kubelet on the Node</li> <li>The <code>k8s_cluster</code> receiver queries the Kubernetes cluster API to retrieve metrics</li> <li>The <code>k8sobjects</code> receiver watches for Kubernetes events (and other resources) on the cluster</li> </ul> </li> <li>Dynatrace allows you to perform powerful queries and analysis of the telemetry data</li> <li>Observing the health of the OpenTelemetry Collectors and data pipeline is critical<ul> <li>The OpenTelemetry Collector exposes self-monitoring metrics in Prometheus format</li> </ul> </li> </ul>"},{"location":"7-opentelemetry-capstone/#continue","title":"Continue","text":"<p>Now that the lab has been completed, let's summarize what we have learned and clean up our Codespaces instance.</p> <ul> <li>Continue to cleanup</li> </ul>"},{"location":"cleanup/","title":"8. Cleanup","text":""},{"location":"cleanup/#clean-up","title":"Clean Up","text":"<p>Help shape our next content \u2014 we\u2019d love your feedback \ud83d\udce3</p> <p>We're always working to improve and make our content more useful and relevant to you. If you have a few minutes, we\u2019d really appreciate your input:</p> <ul> <li>Take 4 minutes to complete our feedback form </li> <li>Or open an issue to share suggestions, topics you'd like us to cover, or examples you'd find helpful.</li> </ul> <p>Your feedback directly shapes what we build next. If there's strong interest in a topic, we\u2019ll prioritize detailed guides, practical examples, and hands-on walkthroughs.</p> <p>Thank you for helping us create better enablement resources for everyone \u2764\ufe0f</p>"},{"location":"cleanup/#summary","title":"Summary","text":"<p>OpenTelemetry is a powerful observability framework that can be used to monitor the health of Kubernetes clusters and containerized workloads.</p> <p>Instrumentation: OpenTelemetry provides libraries and agents to instrument your Kubernetes applications. This means adding code to your applications to collect telemetry data such as traces, metrics, and logs.</p> <p>Data Collection: Once instrumented, OpenTelemetry collects telemetry data from your applications running in the Kubernetes cluster. This data includes information about application performance, resource usage, and error rates.</p> <p>Exporters: OpenTelemetry supports various exporters to send the collected telemetry data to different backends for analysis. Using the OpenTelemetry Collector is the preferred approach to shipping this data to Dynatrace.</p> <p>Visualization and Analysis: By exporting telemetry data to Dynatrace, you can visualize and analyze the health of your Kubernetes cluster. For example, you can use DQL to create dashboards that display metrics like CPU usage, memory consumption, and request latency.</p> <p>Alerting: With the collected data, you can set up alerts to notify you of any issues in your Kubernetes cluster. For instance, you can configure alerts for high error rates or resource exhaustion.</p> <p>By using OpenTelemetry in this way, you can gain deep insights into the performance and health of your Kubernetes clusters, helping you to identify and resolve issues more effectively.</p>"},{"location":"cleanup/#references","title":"References","text":"<p>Dynatrace OpenTelemetry</p> <p>Dynatrace OpenTelemetry Collector</p> <p>Dynatrace OpenTelemetry Collector Use Cases</p> <p>OpenTelemetry Demo Astronomy Shop</p>"},{"location":"cleanup/#delete-codespaces-instance","title":"Delete Codespaces Instance","text":"<p>Deleting the codespace from inside the container</p> <p>We like to make your life easier, for convenience there is a function loaded in the shell of the Codespace for deleting the codespace, just type <code>deleteCodespace</code>. This will trigger the deletion of the codespace.</p> <p>Another way to do this is by going to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token needed for this lab.</p>"},{"location":"snippets/admonitions/","title":"Admonitions","text":"<p>Note</p> <p>This is a Note </p> <p>Abstract</p> <p>This is an abstract</p> <p>Tipp</p> <p>This is a tipp </p> <p>Success</p> <p>This is a success </p> <p>Question</p> <p>This is a success </p> <p>Failure</p> <p>This is a failure </p> <p>Danger</p> <p>This is a danger </p> <p>Info</p> <p>This is a info</p> <p>Warning</p> <p>This is a Warning </p> <p>This is an Example admonition</p> <p>This is an example</p> This is a bug and is collapsable <p>This is a bug</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy - experiment, share feedback, and help shape the future</p> <p>This repository is part of an enablement project created by the Center of Excellence at Dynatrace. Our mission is to empower you to explore and adopt these resources to accelerate innovation. Support is community-driven and provided exclusively via GitHub Issues.</p> <p>We will make every effort to assist and address reported problems, but please note:</p> <ul> <li>The materials are provided \u201cas-is\u201d, without any warranties or guarantees.</li> <li>Use of this technology is at your own discretion and risk.</li> </ul> <p>We encourage you to experiment, share feedback, and help shape the future. Start building today!</p>"},{"location":"snippets/dt-enablement/","title":"Dt enablement","text":"<p>This Codespace leverages the Dynatrace Enablement Framework, providing a robust and flexible development environment. Key features include:</p> <ul> <li>Seamless operation within GitHub Codespaces, as a remote container, or locally via Docker.</li> <li>Cross-compilation support for both AMD and ARM architectures, ensuring broad compatibility.</li> <li>Adherence to industry standards and best practices to optimize the developer experience.</li> <li>Real-time observability of Kubernetes clusters using Dynatrace Full-Stack monitoring.</li> <li>Integrated Dynatrace MCP Server to deliver deep, actionable insights across distributed systems.</li> </ul> <p>To learn more about the Dynatrace Enablement Framework and how it can enhance your development workflow, please refer to the official documentation </p>"},{"location":"snippets/feedback/","title":"Feedback","text":"<p>Help shape our next content \u2014 we\u2019d love your feedback \ud83d\udce3</p> <p>We're always working to improve and make our content more useful and relevant to you. If you have a few minutes, we\u2019d really appreciate your input:</p> <ul> <li>Take 4 minutes to complete our feedback form </li> <li>Or open an issue to share suggestions, topics you'd like us to cover, or examples you'd find helpful.</li> </ul> <p>Your feedback directly shapes what we build next. If there's strong interest in a topic, we\u2019ll prioritize detailed guides, practical examples, and hands-on walkthroughs.</p> <p>Thank you for helping us create better enablement resources for everyone \u2764\ufe0f</p>"},{"location":"snippets/requirements/","title":"Requirements","text":"<p>Requirements</p> <ul> <li>A Dynatrace SaaS Tenant with DPS license (sign up here)<ul> <li>Live, Sprint, or Dev environment</li> <li>Full administrator access to the account and tenant</li> </ul> </li> <li>A GitHub account to interact with the demo repository and run a Codespaces instance<ul> <li>Codespaces core-hours and storage available (GitHub Billing &amp; Licensing)</li> </ul> </li> </ul>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}