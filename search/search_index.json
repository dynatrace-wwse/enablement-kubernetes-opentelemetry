{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. About","text":""},{"location":"#kubernetes-opentelemetry","title":"Kubernetes OpenTelemetry","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"#lab-overview","title":"Lab Overview","text":"<p>During this hands-on training, we\u2019ll learn how to capture logs, traces, and metrics from Kubernetes using OpenTelemetry and ship them to Dynatrace for analysis.  This will demonstrate how to use Dynatrace with OpenTelemetry; without any Dynatrace native components installed on the Kubernetes cluster (Operator, OneAgent, ActiveGate, etc.).</p> <p>Lab tasks:</p> <ol> <li> <p>OpenTelemetry Logs</p> <ul> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for log enrichment</li> <li>Query and visualize logs in Dynatrace using DQL</li> </ul> </li> <li> <p>OpenTelemetry Traces</p> <ul> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for span enrichment</li> <li>Analyze application reliability via traces in Dynatrace</li> </ul> </li> <li> <p>OpenTelemetry Metrics</p> <ul> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Query and visualize metrics in Dynatrace using DQL</li> </ul> </li> <li> <p>OpenTelemetry Capstone</p> <ul> <li>Deploy 4 OpenTelemetry Collectors</li> <li>Configure OpenTelemetry Collector service pipeline for data enrichment</li> <li>Analyze metrics, traces, and logs in Dynatrace</li> <li>Observe OpenTelemetry Collector health in Dynatrace</li> </ul> </li> </ol>"},{"location":"#technical-specification","title":"Technical Specification","text":""},{"location":"#technologies-used","title":"Technologies Used","text":"<ul> <li>Dynatrace</li> <li>Kubernetes Kind<ul> <li>tested on Kind tag 0.27.0</li> </ul> </li> <li>Cert Manager - *prerequisite for OpenTelemetry Operator<ul> <li>tested on cert-manager v1.15.3</li> </ul> </li> <li>Dynatrace Operator<ul> <li>tested on v1.4.2 (April 2025)</li> </ul> </li> <li>Dynatrace OneAgent<ul> <li>tested on v1.309 (April 2025)</li> </ul> </li> </ul>"},{"location":"#reference-architecture","title":"Reference Architecture","text":""},{"location":"#continue","title":"Continue","text":"<p>In the next section, we'll review the prerequisites for this lab needed before launching our Codespaces instance.</p> <ul> <li>Continue to Getting Started</li> </ul>"},{"location":"2-getting-started/","title":"2. Getting started","text":""},{"location":"2-getting-started/#getting-started","title":"Getting Started","text":"<p>Requirements</p> <ul> <li>A Dynatrace SaaS Tenant with DPS license (sign up here)<ul> <li>Live, Sprint, or Dev environment</li> <li>Full administrator access to the account and tenant</li> </ul> </li> <li>A GitHub account to interact with the demo repository and run a Codespaces instance<ul> <li>Codespaces core-hours and storage available (GitHub Billing &amp; Licensing)</li> </ul> </li> </ul>"},{"location":"2-getting-started/#prerequisites","title":"Prerequisites","text":"<p>You will need full administrator access to a Dynatrace SaaS tenant with a DPS license.</p> <ul> <li>Generate Dynatrace Access Token</li> </ul>"},{"location":"2-getting-started/#generate-dynatrace-access-token","title":"Generate Dynatrace Access Token","text":"<p>Generate a new API access token with the following scopes:</p> <p><pre><code>Ingest events\nIngest logs\nIngest metrics\nIngest OpenTelemetry traces\n</code></pre> See Related Dynatrace API Token Creation Documentation</p> <p></p>"},{"location":"2-getting-started/#continue","title":"Continue","text":"<p>In the next section, we'll launch our Codespaces instance.</p> <ul> <li>Continue to Codespaces</li> </ul>"},{"location":"3-codespaces/","title":"3. Codespaces","text":""},{"location":"3-codespaces/#codespaces","title":"Codespaces","text":""},{"location":"3-codespaces/#create-codespace","title":"Create Codespace","text":"<p>Click to open Codespaces for this lab repository:</p> <p></p> <p>Codespace Configuration</p> <ul> <li>Branch<ul> <li>select the main branch</li> </ul> </li> <li>Dev container configuration<ul> <li>select Dynatrace Enablement Container</li> </ul> </li> <li>Machine type<ul> <li>select 4-core</li> </ul> </li> <li>Region<ul> <li>select any region, preferably one closest to your Dynatrace tenant</li> </ul> </li> </ul>"},{"location":"3-codespaces/#wait-for-codespace","title":"Wait for Codespace","text":"<p>We know your time is very valuable. This codespace takes around 7-10 minutes to be fully operational. A local Kubernetes (kind) cluster will be configured and in it a sample application, Astronomy Shop, will be deployed. To make your experience better, we are also installing and configuring tools like:</p> <p>k9s kubectl helm node jq python3 gh</p>"},{"location":"3-codespaces/#explore-codespace","title":"Explore Codespace","text":"<p>Your Codespace has now deployed the following resources:</p> <ul> <li>A local Kubernetes (kind) cluster, with some pre-deployed apps that will be used later in the demo.</li> </ul> <p>After a couple of minutes, you'll see this screen in your Codespaces terminal. It contains the links to the UI of the application which we will be using for our hands-on training.</p> <p>Sample output: </p>"},{"location":"3-codespaces/#validate-astronomy-shop","title":"Validate Astronomy Shop","text":"<p>When the Codespace instance is idle, validate the <code>astronomy-shop</code> pods are running.</p> <p>Command: <pre><code>kubectl get pods -n astronomy-shop\n</code></pre></p> <p></p>"},{"location":"3-codespaces/#tips-tricks","title":"Tips &amp; Tricks","text":"<p>We want to boost your learning and try to make your experience as smooth as possible with Dynatrace trainings. Your Codespaces have a couple of convenience features added. </p>"},{"location":"3-codespaces/#show-the-greeting","title":"Show the greeting","text":"<p>In the terminal, there are functions loaded for your convenience. By creating a new terminal the greeting will be shown that includes the links to the exposed apps, the Github  pages, the Github Repository, the Dynatrace Tenant that is bound to this devcontainer (if applicable) and some of the tools installed.</p> <p>You can create a new terminal directly in VSCode, type <code>zsh</code> or call the function <code>printGreeting</code> and that will print the greeting with the most relevant information.</p>"},{"location":"3-codespaces/#navigating-in-your-local-kubernetes","title":"Navigating in your local Kubernetes","text":"<p>The client <code>kubectl</code> and <code>k9s</code> are configured so you can navigate in your local Kubernetes.  </p>"},{"location":"3-codespaces/#troubleshooting","title":"Troubleshooting","text":""},{"location":"3-codespaces/#astronomy-shop","title":"Astronomy Shop","text":"<p>If you encounter problems with the Astronomy Shop app deployed in the <code>astronomy-shop</code> namespace, you can easily recycle the pods.</p> <p>Recycle pods: <pre><code>kubectl delete pods --all -n astronomy-shop\n</code></pre></p> <p>But before doing so, if you want to see what is happening we recommend the following: </p> <p>Verify all astronomy-shop pods <pre><code>kubectl get pods -n astronomy-shop\n</code></pre></p> <p>Check for events in the astronomy-shop namespace <pre><code>kubectl get events -n astronomy-shop\n</code></pre></p> <p>Check for system and cluster events  <pre><code>kubectl get events -n kube-system\nkubectl get events -n default\n</code></pre></p>"},{"location":"3-codespaces/#app-exposure","title":"App exposure","text":"<p>The astronomy-shop application is exposed via NodePort and it's mapping port 8080 to Cluster port 30100.</p> <p>Verify service: <pre><code>kubectl get svc astronomy-shop-frontendproxy -n astronomy-shop\n</code></pre></p>"},{"location":"3-codespaces/#finish-codespace-setup","title":"Finish Codespace Setup","text":""},{"location":"3-codespaces/#define-workshop-user-variables","title":"Define workshop user variables","text":"<p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre>"},{"location":"3-codespaces/#deploy-opentelemetry-operator","title":"Deploy OpenTelemetry Operator","text":"<p>Move to the base directory</p> <p>Command: <pre><code>cd $BASE_DIR\npwd\n</code></pre> Sample output:</p> <p>/workspaces/enablement-kubernetes-opentelemetry</p> <p>You should find yourself at the base directory of the repository. If not, then navigate to it.</p> <p>Create <code>dynatrace</code> namespace</p> <p>Create the <code>dynatrace</code> namespace.  This is where we'll deploy the OpenTelemetry Collectors.</p> <p>Command: <pre><code>kubectl create namespace dynatrace\n</code></pre></p> <p>Sample output: <pre><code>&gt; namespace/dynatrace created\n</code></pre></p> <p>Create <code>dynatrace-otelcol-dt-api-credentials</code> secret</p> <p>The secret holds the API endpoint and API token that OpenTelemetry data will be sent to.</p> <p>Command: <pre><code>kubectl create secret generic dynatrace-otelcol-dt-api-credentials --from-literal=DT_ENDPOINT=$DT_ENDPOINT --from-literal=DT_API_TOKEN=$DT_API_TOKEN -n dynatrace\n</code></pre> Sample output:</p> <pre><code>&gt; secret/dynatrace-otelcol-dt-api-credentials created\n</code></pre> <p>Deploy <code>cert-manager</code>, pre-requisite for <code>opentelemetry-operator</code></p> <p>Cert-Manager Documentation</p> <p>Command: <pre><code>kubectl apply -f cluster-manifests/cert-manager.yaml\n</code></pre></p> <p>Sample output:</p> <p>namespace/cert-manager created\\ customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\\ customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created</p> <p>Wait 30-60 seconds for cert-manager to finish initializing before continuing.</p> <p>Deploy <code>opentelemetry-operator</code></p> <p>The OpenTelemetry Operator will deploy and manage the custom resource <code>OpenTelemetryCollector</code> deployed on the cluster.</p> <p>Command: <pre><code>kubectl apply -f cluster-manifests/opentelemetry-operator.yaml\n</code></pre></p> <p>Sample output:</p> <p>namespace/opentelemetry-operator-system created\\ customresourcedefinition.apiextensions.k8s.io/instrumentations.opentelemetry.io created\\ customresourcedefinition.apiextensions.k8s.io/opampbridges.opentelemetry.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/opentelemetry-operator-validating-webhook-configuration configured</p> <p>Wait 30-60 seconds for opentelemetry-operator-controller-manager to finish initializing before continuing.</p> <p>Validate that the OpenTelemetry Operator components are running.</p> <p>Command: <pre><code>kubectl get pods -n opentelemetry-operator-system\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE opentelemetry-operator-controller-manager-5d746dbd64-rf9st 2/2 Running 0 1m"},{"location":"3-codespaces/#continue","title":"Continue","text":"<p>In the next section, we'll ship logs from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Logs</li> </ul>"},{"location":"4-opentelemetry-logs/","title":"4. OpenTelemetry Logs","text":""},{"location":"4-opentelemetry-logs/#opentelemetry-logs","title":"OpenTelemetry Logs","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a DaemonSet (Node Agent) to collect pod/container logs from a Kubernetes cluster and ship them to Dynatrace.  Additionally, we'll deploy the OpenTelemetry Collector as a Deployment (Gateway) to watch Kubernetes Events from the Cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for log enrichment</li> <li>Query and visualize logs in Dynatrace using DQL</li> </ol> <p></p> <ul> <li>Learn More</li> </ul>"},{"location":"4-opentelemetry-logs/#prerequisites","title":"Prerequisites","text":"<p>Import Notebook into Dynatrace</p> <p>Notebook</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the logs module directory</p> <p>Command: <pre><code>cd $BASE_DIR/lab-modules/dt-k8s-otel-o11y-logs\n</code></pre></p>"},{"location":"4-opentelemetry-logs/#opentelemetry-collector-for-logs","title":"OpenTelemetry Collector for Logs","text":"<p>Dynatrace Documentation</p>"},{"location":"4-opentelemetry-logs/#deploy-opentelemetry-collector","title":"Deploy OpenTelemetry Collector","text":"<p>Dynatrace Distro - Daemonset (Node Agent) Dynatrace Documentation</p> <p>Pod (and container) logs are written to the filesystem of the Node where the pod is running.  Therefore the Collector must be deployed as a Daemonset to read the log files on the local Node.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-logs\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"daemonset\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-8q8tz 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#filelog-receiver","title":"<code>filelog</code> Receiver","text":"<p>OpenTelemetry Documentation</p> <p>The Filelog Receiver tails and parses logs from files. Although it\u2019s not a Kubernetes-specific receiver, it is still the de facto solution for collecting any logs from Kubernetes.  Logs from the Kubernetes Node's filesystem will be read from the Collector running on that Node.  This is why the Collector is deployed as a Daemonset and not a Deployment (or Sidecar).</p> <p>The Filelog Receiver is composed of Operators that are chained together to process a log. Each Operator performs a simple responsibility, such as parsing a timestamp or JSON. Configuring a Filelog Receiver is not trivial.  Refer to the documentation for details.</p> <pre><code>config: |\n    receivers:\n      filelog:\n        ...\n    service:\n      pipelines:\n        logs:\n          receivers: [filelog]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(log.file.path) and isNotNull(log)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, k8s.namespace.name, k8s.pod.name, k8s.container.name, content, log.file.path\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>Add Kubernetes Attributes with the <code>k8sattributes</code> Processor</p> <p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p>"},{"location":"4-opentelemetry-logs/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the collector the following permissions via a ClusterRole.</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-logs\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\", \"nodes\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-logs.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-logs created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-logs-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-logs-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-logs\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-logs-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-logs-crb created</p>"},{"location":"4-opentelemetry-logs/#add-k8sattributes-processor","title":"Add <code>k8sattributes</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n    auth_type: \"serviceAccount\"\n    passthrough: false\n        filter:\n        node_from_env_var: KUBE_NODE_NAME\n    extract:\n        metadata:\n            - k8s.namespace.name\n            - k8s.deployment.name\n            - k8s.daemonset.name\n            - k8s.job.name\n            - k8s.cronjob.name\n            - k8s.replicaset.name\n            - k8s.statefulset.name\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.node.name\n            - k8s.container.name\n            - container.id\n            - container.image.name\n            - container.image.tag\n        labels:\n        - tag_name: app.label.component\n            key: app.kubernetes.io/component\n            from: pod\n    pod_association:\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.uid\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.name\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.ip\n        - sources:\n            - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-dns4x 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, k8s.namespace.name, k8s.deployment.name, k8s.pod.name, k8s.container.name, app.label.component, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#resourcedetection-processor","title":"resourcedetection Processor","text":"<p>The resource detection processor can be used to detect resource information from the host, in a format that conforms to the OpenTelemetry resource semantic conventions, and append or override the resource value in telemetry data with this information.  Detectors are available for AWS, Azure, GCP, and several other platforms; see the documentation for more details.</p> <p>This processor is a great plugin for adding attributes such as <code>cloud.account.id</code> and <code>k8s.cluster.name</code> to the telemetry.</p>"},{"location":"4-opentelemetry-logs/#add-resourcedetection-processor","title":"Add <code>resourcedetection</code> Processor","text":"<p>OpenTelemetry Documentation</p> <pre><code>processors:\n  resourcedetection/gcp:\n    detectors: [env, gcp]\n    timeout: 2s\n    override: false\n</code></pre> <p>note: for this lab, the Kind cluster does not have cloud metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: cloud.account.id\n    value: dt-k8s-o11y-account\n    action: insert\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-03.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-fbtk5 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(cloud.account.id) and isNotNull(k8s.cluster.name)\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, cloud.account.id, k8s.cluster.name, k8s.namespace.name, k8s.deployment.name, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#resource-processor","title":"resource Processor","text":""},{"location":"4-opentelemetry-logs/#add-resource-processor","title":"Add <code>resource</code> Processor","text":"<p>OpenTelemetry Documentaiton</p> <p>The <code>resource</code> processor allows us to directly add, remove, or change resource attributes on the telemetry.  View the documentation for more details.</p> <p>We will use this processor to make the follow changes to our telemetry:</p> <ul> <li><code>k8s.pod.ip</code> values in our log data are either the same or invalid; delete the useless attribute</li> <li><code>telemetry.sdk.name</code> set to <code>opentelemetry</code> will allow us to easily identify logs captured through OpenTelemetry</li> <li><code>dynatrace.otel.collector</code> is a non-standardized attribute that we made up to help us identify which Collector captured this data</li> <li><code>dt.security_context</code> is a Dynatrace specific attribute that we use to manage user permissions to the telemetry<ul> <li>This could also be set using OpenPipeline, but this puts control of this attribute's value at the app/infra layer (optionally)</li> </ul> </li> </ul> <p><pre><code>processors:\n    resource:\n        attributes:\n        - key: k8s.pod.ip\n          action: delete\n        - key: telemetry.sdk.name\n          value: opentelemetry\n          action: insert\n        - key: dynatrace.otel.collector\n          value: dynatrace-logs\n          action: insert\n        - key: dt.security_context\n          from_attribute: k8s.cluster.name\n          action: insert\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-04.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre> Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-xx6km 1/1 Running 0 1m <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter isNotNull(dt.security_context)\n| filter isNotNull(cloud.account.id) and isNotNull(k8s.cluster.name)\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(k8s.deployment.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, loglevel, status, dt.security_context, dynatrace.otel.collector, cloud.account.id, k8s.cluster.name, k8s.namespace.name, k8s.deployment.name, content\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#otlp-exporter","title":"OTLP Exporter","text":"<p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating logs (traces and metrics too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these logs to be shipped to Dynatrace as well.</p> <p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors. <pre><code>config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        logs:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre></p> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/logs/otel-collector-logs-crd-05.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-logs configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-logs-collector-gu0rm 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#customize-astronomy-shop-helm-values","title":"Customize astronomy-shop helm values","text":"<p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed -i \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command:</p> <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> <p>Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter k8s.namespace.name == \"astronomy-shop\" and isNotNull(service.name)\n| sort timestamp desc\n| limit 100\n| fields timestamp, content, k8s.cluster.name, k8s.pod.name, service.namespace, service.name, telemetry.sdk.language, otel.scope.name\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#opentelemetry-collector-for-events","title":"OpenTelemetry Collector for Events","text":"<p>OpenTelemetry Documentation</p> <p>The Kubernetes Objects receiver collects, either by pulling or watching, objects from the Kubernetes API server. The most common use case for this receiver is watching Kubernetes events, but it can be used to collect any type of Kubernetes object.</p>"},{"location":"4-opentelemetry-logs/#k8sobjects-receiver","title":"<code>k8sobjects</code> Receiver","text":"<p>https://opentelemetry.io/docs/kubernetes/collector/components/#kubernetes-objects-receiver</p> <p>Our goal is to capture any events related to the <code>astronomy-shop</code> and <code>dynatrace</code> namespaces.</p> <pre><code>receivers:\n  k8sobjects/events:\n    auth_type: serviceAccount\n    objects:\n      - name: events\n        mode: watch\n        namespaces: [astronomy-shop,dynatrace]\n</code></pre> <p>The <code>k8sobjects</code> receiver is only available on the Contrib Distro of the OpenTelemetry Collector.  Therefore we must deploy a new Collector using the <code>contrib</code> image.</p>"},{"location":"4-opentelemetry-logs/#configure-kubernetes-rbac_1","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes events</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. Since service accounts are the only authentication option you must give the service account the proper access. For any object you want to collect you need to ensure the name is added to the cluster role. </p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-events\nrules:\n- apiGroups: [\"\"]\n  resources: [\"events\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-events.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-events created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-events-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-events-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-events\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-events-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-events-crb created</p> <p>Add <code>k8sobjects</code> receiver to collect Kubernetes events as logs</p> <p>OpenTelemetry Documentation</p> <pre><code>receivers:\n  k8sobjects/events:\n    auth_type: serviceAccount\n    objects:\n      - name: events\n        mode: watch\n        namespaces: [astronomy-shop,dynatrace]\n</code></pre> <p>Deploy OpenTelemetry Collector - Contrib Distro - Deployment (Gateway)</p> <p>OpenTelemetry Documentation</p> <p>Since the receiver gathers telemetry for the cluster as a whole, only one instance of the receiver is needed across the cluster in order to collect all the data.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-events\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"otel/opentelemetry-collector-contrib:0.103.0\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/events/otel-collector-events-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-events created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-events-collector-559d5b9d77-rb26d 1/1 Running 0 1m"},{"location":"4-opentelemetry-logs/#generate-events","title":"Generate Events","text":"<p>Generate events using deployment scale command</p> <p>Kubernetes Documentation</p> <p>We can generate new Kubernetes events related to the <code>astronomy-shop</code> namespace by scaling a deployment up and then scaling it back down.</p> <p>Command: <pre><code>kubectl scale deployment astronomy-shop-imageprovider -n astronomy-shop --replicas=2\n</code></pre> Sample output:</p> <p>deployment.apps/astronomy-shop-imageprovider scaled</p> <p>Command: <pre><code>kubectl scale deployment astronomy-shop-imageprovider -n astronomy-shop --replicas=1\n</code></pre> Sample output:</p> <p>deployment.apps/astronomy-shop-imageprovider scaled</p> <p>Query logs in Dynatrace</p> <p>DQL: <pre><code>fetch logs\n| filter dynatrace.otel.collector == \"dynatrace-events\" and event.domain == \"k8s\" and k8s.resource.name == \"events\"\n| filter object.metadata.namespace == \"astronomy-shop\"\n| sort timestamp desc\n| limit 100\n| fields timestamp, k8s.cluster.name, {object.metadata.namespace, alias: k8s.namespace.name}, object.message, object.reason, event.name\n</code></pre> Result:</p> <p></p>"},{"location":"4-opentelemetry-logs/#wrap-up","title":"Wrap Up","text":""},{"location":"4-opentelemetry-logs/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect logs, enrich log attributes for better context, and ship those logs to Dynatrace for analysis.</p> <ul> <li>The OpenTelemetry Collector was deployed as a DaemonSet, behaving as an Agent running on each Node</li> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship logs to Dynatrace<ul> <li>The <code>filelog</code> receiver scrapes logs from the Node filesystem and parses the contents</li> <li>The <code>otlp</code> receiver receives logs that are exported from agents, SDKs, and other Collectors</li> <li>The <code>k8sattributes</code> processor enriches the logs with Kubernetes attributes</li> <li>The <code>resourcedetection</code> processor enriches the logs with cloud and cluster attributes</li> <li>The <code>resource</code> processor enriches the logs with custom (resource) attributes</li> </ul> </li> <li>The Community Contrib Distro of OpenTelemetry Collector includes modules needed to ship events to Dynatrace<ul> <li>The <code>k8sobjects</code> receiver watches for Kubernetes events (and other resources) on the cluster</li> </ul> </li> <li>Dynatrace DQL (via Notebooks) allows you to perform powerful queries and analysis of the log data</li> </ul>"},{"location":"4-opentelemetry-logs/#continue","title":"Continue","text":"<p>In the next section, we'll ship traces and spans from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Traces</li> </ul>"},{"location":"5-opentelemetry-traces/","title":"5. OpenTelemetry Traces","text":""},{"location":"5-opentelemetry-traces/#opentelemetry-traces","title":"OpenTelemetry Traces","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a Deployment (Gateway) to collect application traces/spans, generated by OpenTelemetry, from a Kubernetes cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for span enrichment</li> <li>Analyze application reliability via traces in Dynatrace</li> </ol> <p> </p> <ul> <li>Learn More</li> </ul>"},{"location":"5-opentelemetry-traces/#prerequisites","title":"Prerequisites","text":"<p>Import Dashboard into Dynatrace</p> <p>Dashboard</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the traces module directory</p> <p>Command: <pre><code>cd $BASE_DIR/lab-modules/dt-k8s-otel-o11y-traces\n</code></pre></p>"},{"location":"5-opentelemetry-traces/#opentelemetry-collector-for-traces","title":"OpenTelemetry Collector for Traces","text":"<p>Dynatrace Documentation</p> <p>Distributed traces and their spans, generated by OpenTelemetry agents and SDKs, are exported from their origin to an <code>otlp</code> receiver.  These traces/spans can be sent directly to Dynatrace, using the OTLP ingest API.  However, it is highly recommended to use the OpenTelemetry Collector to process, filter, and manipulate the data first.</p>"},{"location":"5-opentelemetry-traces/#otlp-receiver","title":"<code>otlp</code> Receiver","text":"<p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors.</p> <pre><code>config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre>"},{"location":"5-opentelemetry-traces/#deploy-opentelemetry-collector-deployment","title":"Deploy OpenTelemetry Collector Deployment","text":"<p>Dynatrace Documentation</p> <p>The gateway collector deployment pattern consists of applications (or other collectors) sending telemetry signals to a single OTLP endpoint provided by one or more collector instances running as a standalone service (for example, a deployment in Kubernetes), typically per cluster, per data center or per region.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-traces\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-ms24p 1/1 Running 0 1m <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Dynatrace Distro</p> <p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating traces (logs and metrics too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these traces to be shipped to Dynatrace as well.</p> <p>Customize astronomy-shop helm values</p> <p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed -i \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p>"},{"location":"5-opentelemetry-traces/#analyze-opentelemetry-traces-in-dynatrace","title":"Analyze OpenTelemetry Traces in Dynatrace","text":"<p>Result:</p> <p>Open the Distributed Traces Classic App to view the traces in Dynatrace (you can use the new Distributed Traces App if available as well).</p> <p></p> <p>Locate a trace from the <code>checkoutservice</code> service with a trace/request name of <code>oteldemo.CheckoutService/PlaceOrder</code>.  This is a nice end-to-end trace.</p> <p></p> <p>Click on a span to see the various attributes that are attached to the span.</p> <p></p> <p>These attributes are good, but we can add more to provide better Kubernetes context to these transactions.</p> <p>Refer to the Dynatrace documentation for more details</p>"},{"location":"5-opentelemetry-traces/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>Add Kubernetes Attributes with the <code>k8sattributes</code> Processor</p> <p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p>"},{"location":"5-opentelemetry-traces/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the processor uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the collector the following permissions via a ClusterRole.</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-traces\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\", \"nodes\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-traces.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-traces created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-traces-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-traces-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-traces\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-traces-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-traces-crb created</p>"},{"location":"5-opentelemetry-traces/#add-k8sattributes-processor","title":"Add <code>k8sattributes</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n    auth_type: \"serviceAccount\"\n    passthrough: false\n        filter:\n        node_from_env_var: KUBE_NODE_NAME\n    extract:\n        metadata:\n            - k8s.namespace.name\n            - k8s.deployment.name\n            - k8s.daemonset.name\n            - k8s.job.name\n            - k8s.cronjob.name\n            - k8s.replicaset.name\n            - k8s.statefulset.name\n            - k8s.pod.name\n            - k8s.pod.uid\n            - k8s.node.name\n            - k8s.container.name\n            - container.id\n            - container.image.name\n            - container.image.tag\n        labels:\n        - tag_name: app.label.component\n            key: app.kubernetes.io/component\n            from: pod\n    pod_association:\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.uid\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.name\n        - sources:\n            - from: resource_attribute\n              name: k8s.pod.ip\n        - sources:\n            - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-xn84p 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Kubernetes Attributes</p> <p>Dynatrace utilizes the <code>service.name</code>, <code>k8s.workload.name</code> and <code>k8s.namespace.name</code> to generate the unified service.</p> <p>Dynatrace Documentation</p> <p>Result:</p> <p>With the additional Kubernetes attributes attached to the spans, Dynatrace will detect new unified services.</p> <p></p> <p>Locate a new trace from the new <code>checkoutservice</code> service with a trace/request name of <code>oteldemo.CheckoutService/PlaceOrder</code>.  Click on a span to see the new resource attributes that have been added to the span.</p> <p></p>"},{"location":"5-opentelemetry-traces/#resourcedetection-processor","title":"resourcedetection Processor","text":""},{"location":"5-opentelemetry-traces/#add-resourcedetection-processor","title":"Add <code>resourcedetection</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The resource detection processor can be used to detect resource information from the host, in a format that conforms to the OpenTelemetry resource semantic conventions, and append or override the resource value in telemetry data with this information.  Detectors are available for AWS, Azure, GCP, and several other platforms; see the documentation for more details.</p> <pre><code>processors:\n  resourcedetection/gcp:\n    detectors: [env, gcp]\n    timeout: 2s\n    override: false\n</code></pre> <p>note: for this lab, the Kind cluster does not have cloud metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: cloud.account.id\n    value: dt-k8s-o11y-account\n    action: insert\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-03.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-rp21d 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Cloud Attributes</p> <p>Result:</p> <p>Locate a new trace from the new <code>checkoutservice</code> service with a trace/request name of <code>oteldemo.CheckoutService/PlaceOrder</code>.  Click on a span to see the new resource attributes that have been added to the span.</p> <p> ** In a real world scenario, <code>cloud.account.id</code> may be considered sensitive data; blurred for this reason.</p>"},{"location":"5-opentelemetry-traces/#resource-processor","title":"resource Processor","text":""},{"location":"5-opentelemetry-traces/#add-resource-processor","title":"Add <code>resource</code> Processor","text":"<p>OpenTelemetry Documentation</p> <p>The <code>resource</code> processor allows us to directly add, remove, or change resource attributes on the telemetry.  View the documentation for more details.</p> <p>We will use this processor to make the follow changes to our telemetry: * <code>k8s.pod.ip</code> values in our data are either the same or invalid; delete the useless attribute * <code>telemetry.sdk.name</code> set to <code>opentelemetry</code> will allow us to easily identify data captured through OpenTelemetry * <code>dynatrace.otel.collector</code> is a non-standardized attribute that we made up to help us identify which Collector captured this data * <code>dt.security_context</code> is a Dynatrace specific attribute that we use to manage user permissions to the telemetry     * This could also be set using OpenPipeline, but this puts control of this attribute's value at the app/infra layer (optionally)</p> <p><pre><code>processors:\n    resource:\n        attributes:\n        - key: k8s.pod.ip\n          action: delete\n        - key: telemetry.sdk.name\n          value: opentelemetry\n          action: insert\n        - key: dynatrace.otel.collector\n          value: dynatrace-traces\n          action: insert\n        - key: dt.security_context\n          from_attribute: k8s.cluster.name\n          action: insert\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/traces/otel-collector-traces-crd-04.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-traces configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-traces-collector-559d5b9d77-ny98q 1/1 Running 0 1m <p>OpenTelemetry Traces in Dynatrace with Custom Resource Attributes</p> <p>Result:</p> <p>Locate a new trace from the new <code>checkoutservice</code> service with a trace/request name of <code>oteldemo.CheckoutService/PlaceOrder</code>.  Click on a span to see the new resource attributes that have been added to the span.</p> <p></p>"},{"location":"5-opentelemetry-traces/#dynatrace-dashboard-with-unified-services-from-opentelemetry","title":"Dynatrace Dashboard with Unified Services from OpenTelemetry","text":"<p>Open the Dashboard that you imported to view the throughput, response time, and failure metrics for the <code>astronomy-shop</code> application services.</p> <p></p>"},{"location":"5-opentelemetry-traces/#wrap-up","title":"Wrap Up","text":""},{"location":"5-opentelemetry-traces/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect traces, enrich span attributes for better context, and ship those traces/spans to Dynatrace for analysis.</p> <ul> <li>The OpenTelemetry Collector was deployed as a Deployment, behaving as a Gateway on the cluster</li> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship traces to Dynatrace<ul> <li>The <code>otlp</code> receiver receives traces (and other signals) from OpenTelemetry exporters via gRPC/HTTP</li> <li>The <code>k8sattributes</code> processor enriches the spans with Kubernetes attributes</li> <li>The <code>resourcedetection</code> processor enriches the spans with cloud and cluster (GCP/GKE) attributes</li> <li>The <code>resource</code> processor enriches the spans with custom (resource) attributes</li> </ul> </li> <li>Dynatrace allows you to perform powerful queries and analysis of the trace/span data</li> </ul>"},{"location":"5-opentelemetry-traces/#continue","title":"Continue","text":"<p>In the next section, we'll ship metrics and datapoints from Kubernetes to Dynatrace using OpenTelemetry.</p> <ul> <li>Continue to OpenTelemetry Metrics</li> </ul>"},{"location":"6-opentelemetry-metrics/","title":"6. OpenTelemetry Metrics","text":""},{"location":"6-opentelemetry-metrics/#opentelemetry-metrics","title":"OpenTelemetry Metrics","text":"<p>In this lab module we'll utilize the OpenTelemetry Collector deployed as a DaemonSet (Node Agent) to collect Node (kubelet) metrics from a Kubernetes cluster and ship them to Dynatrace.  Additionally, we'll utilize a second OpenTelemetry Collector deployed as a Deployment (Gateway) to collect Cluster (Kubernetes API) metrics from the Kubernetes cluster and ship them to Dynatrace.</p> <p>Lab tasks:</p> <ol> <li>Deploy OpenTelemetry Collector as a DaemonSet</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Deploy OpenTelemetry Collector as a Deployment</li> <li>Configure OpenTelemetry Collector service pipeline for metric enrichment</li> <li>Query and visualize metrics in Dynatrace using DQL</li> </ol> <ul> <li>Learn More</li> </ul>"},{"location":"6-opentelemetry-metrics/#prerequisites","title":"Prerequisites","text":"<p>Import Notebook into Dynatrace</p> <p>Notebook</p> <p>Define workshop user variables</p> <p>In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the metrics module directory</p> <p>Command: <pre><code>cd $BASE_DIR/lab-modules/dt-k8s-otel-o11y-metrics\n</code></pre></p>"},{"location":"6-opentelemetry-metrics/#collector-for-node-metrics","title":"Collector for Node Metrics","text":"<p>Kubernetes Node Metrics</p> <p>Each Kubernetes Node runs a kubelet that includes an API server. The <code>kubeletstats</code> Receiver connects to that kubelet via the API server to collect metrics about the node and the workloads running on the node.</p>"},{"location":"6-opentelemetry-metrics/#deploy-opentelemetry-collector","title":"Deploy OpenTelemetry Collector","text":"<p>Contrib Distro - Daemonset (Node Agent)</p> <p>The <code>kubeletstats</code> receiver is only available on the Contrib Distro of the OpenTelemetry Collector.  Therefore we must deploy a new Collector using the <code>contrib</code> image.</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-metrics-node\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  env:\n    - name: K8S_NODE_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n  mode: \"daemonset\"\n  image: \"otel/opentelemetry-collector-contrib:0.103.0\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-node-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-node created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-node-collector-2kzlp 1/1 Running 0 1m"},{"location":"6-opentelemetry-metrics/#configure-kubernetes-rbac","title":"Configure Kubernetes RBAC","text":"<p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p>Since the receiver uses the Kubernetes API, it needs the correct permission to work correctly. For most use cases, you should give the service account running the Collector the following permissions via a ClusterRole.</p> <pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole-metrics\nrules:\n  - apiGroups: ['']\n    resources: ['events', 'namespaces', 'namespaces/status', 'nodes', 'nodes/spec', 'nodes/stats', 'nodes/proxy', 'pods', 'pods/status', 'replicationcontrollers', 'replicationcontrollers/status', 'resourcequotas', 'services']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['apps']\n    resources: ['daemonsets', 'deployments', 'replicasets', 'statefulsets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['extensions']\n    resources: ['daemonsets', 'deployments', 'replicasets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['batch']\n    resources: ['jobs', 'cronjobs']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['autoscaling']\n    resources: ['horizontalpodautoscalers']\n    verbs: ['get', 'list', 'watch']\n</code></pre> <p>Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-metrics.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-metrics created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service account</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-metrics-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-metrics-node-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole-metrics\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-metrics-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-metrics-crb created</p>"},{"location":"6-opentelemetry-metrics/#kubeletstats-receiver","title":"<code>kubeletstats</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p>By default, metrics will be collected for pods and nodes, but you can configure the receiver to collect container and volume metrics as well. The receiver also allows configuring how often the metrics are collected:</p> <pre><code>config: |\n    receivers:\n      kubeletstats:\n        collection_interval: 30s\n        auth_type: 'serviceAccount'\n        endpoint: '${env:K8S_NODE_NAME}:10250'\n        insecure_skip_verify: true\n        metric_groups:\n          - node\n          - pod\n          - container\n</code></pre> <p>Default Metrics: OpenTelemetry Documentation</p> <p>note: for this lab, the Kind cluster does not have cluster metadata to collect.  These values will be spoofed for the purposes of this lab.</p> <pre><code>resource/kind:\n  attributes:\n  - key: k8s.cluster.name\n    value: dt-k8s-o11y-kind\n    action: insert\n</code></pre> <p>Query Node metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries node_cpu = avg(k8s.node.cpu.utilization), by: {k8s.cluster.name, k8s.node.name}\n</code></pre> Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#k8sattributes-processor","title":"k8sattributes Processor","text":"<p>The Kubernetes Attributes Processor automatically discovers Kubernetes pods, extracts their metadata, and adds the extracted metadata to spans, metrics, and logs as resource attributes.</p> <p>The Kubernetes Attributes Processor is one of the most important components for a collector running in Kubernetes. Any collector receiving application data should use it. Because it adds Kubernetes context to your telemetry, the Kubernetes Attributes Processor lets you correlate your application\u2019s traces, metrics, and logs signals with your Kubernetes telemetry, such as pod metrics and traces.</p> <p>Add <code>k8sattributes</code> processor</p> <p>OpenTelemetry Documentation</p> <p>The <code>k8sattributes</code> processor will query metadata from the cluster about the k8s objects.  The Collector will then marry this metadata to the telemetry.</p> <p><pre><code>k8sattributes:\n  auth_type: \"serviceAccount\"\n  passthrough: false\n  filter:\n    node_from_env_var: KUBE_NODE_NAME\n  extract:\n    metadata:\n      - k8s.namespace.name\n      - k8s.deployment.name\n      - k8s.daemonset.name\n      - k8s.job.name\n      - k8s.cronjob.name\n      - k8s.replicaset.name\n      - k8s.statefulset.name\n      - k8s.pod.name\n      - k8s.pod.uid\n      - k8s.node.name\n      - k8s.container.name\n      - container.id\n      - container.image.name\n      - container.image.tag\n    labels:\n      - tag_name: app.label.component\n        key: app.kubernetes.io/component\n        from: pod\n    pod_association:\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.uid\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.name\n      - sources:\n          - from: resource_attribute\n            name: k8s.pod.ip\n      - sources:\n          - from: connection\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-node-crd-02.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-node configured</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-node-collector-drk1p 1/1 Running 0 1m <p>Query Pod metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries pod_cpu = avg(k8s.pod.cpu.utilization), by: { k8s.pod.name, k8s.node.name, k8s.namespace.name, k8s.deployment.name, k8s.cluster.name, k8s.pod.uid }\n| filter k8s.namespace.name == \"astronomy-shop\" and k8s.deployment.name == \"astronomy-shop-productcatalogservice\"\n</code></pre></p> <p>Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#collector-for-cluster-metrics","title":"Collector for Cluster Metrics","text":"<p>The Kubernetes Cluster Receiver collects metrics and entity events about the cluster as a whole using the Kubernetes API server. Use this receiver to answer questions about pod phases, node conditions, and other cluster-wide questions.</p>"},{"location":"6-opentelemetry-metrics/#deploy-opentelemetry-collector_1","title":"Deploy OpenTelemetry Collector","text":"<p>Contrib Distro - Deployment (Gateway)</p> <p>OpenTelemetry Documentation</p> <p>The <code>k8s_cluster</code> receiver is only available on the Contrib Distro of the OpenTelemetry Collector.  Therefore we must deploy a new Collector using the <code>contrib</code> image.</p> <p>Since the receiver gathers telemetry for the cluster as a whole, only one instance of the receiver is needed across the cluster in order to collect all the data.  The Collector will be deployed as a Deployment (Gateway).</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-metrics-cluster\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"otel/opentelemetry-collector-contrib:0.103.0\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/metrics/otel-collector-metrics-cluster-crd-01.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-metrics-cluster created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-metrics-cluster-collector-7bd8dc4995-6sgs2 1/1 Running 0 1m"},{"location":"6-opentelemetry-metrics/#k8s_cluster-receiver","title":"<code>k8s_cluster</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p><pre><code>config: |\n    receivers:\n      k8s_cluster:\n        collection_interval: 60s\n        node_conditions_to_report: [ \"Ready\", \"MemoryPressure\", \"DiskPressure\" ]\n        allocatable_types_to_report: [ \"cpu\",\"memory\" ]\n        metadata_collection_interval: 5m\n</code></pre> Default Metrics: OpenTelemetry Documentation</p> <p>Query Deployment metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries pods_avail = min(k8s.deployment.available), by: {k8s.cluster.name, k8s.deployment.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p>"},{"location":"6-opentelemetry-metrics/#export-application-metrics","title":"Export Application Metrics","text":"<p>The <code>astronomy-shop</code> demo application has the OpenTelemetry agents and SDKs already instrumented.  These agents and SDKs are generating metrics (traces and logs too) that are being exported to a Collector running within the <code>astronomy-shop</code> namespace bundled into the application deployment.  We want these metrics to be shipped to Dynatrace as well.</p>"},{"location":"6-opentelemetry-metrics/#otlp-receiver","title":"<code>otlp</code> receiver","text":"<p>OpenTelemetry Documentation</p> <p>Adding the <code>otlp</code> receiver allows us to receive telemetry from otel exporters, such as agents and other collectors.</p> <pre><code>config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\n    service:\n      pipelines:\n        metrics:\n          receivers: [otlp]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Contrib Distro</p> <p>Customize astronomy-shop helm values</p> <p>OpenTelemetry data created by agents and SDKs should include <code>service.name</code> and <code>service.namespace</code> attributes.  We will make the <code>service.namespace</code> unique to our deployment using our <code>NAME</code> environment variable declared earlier, using a <code>sed</code> command on the Helm chart's <code>values.yaml</code> file.</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed -i \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Our <code>collector-values.yaml</code> contains new configurations for the application so that the <code>astronomy-shop</code> Collector includes exporters that ship to the Collectors deployed in the <code>dynatrace</code> namespace.</p> <pre><code>exporters:\n  # Dynatrace OTel Collectors\n  otlphttp/dttraces:\n    endpoint: http://dynatrace-traces-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtlogs:\n    endpoint: http://dynatrace-logs-collector.dynatrace.svc.cluster.local:4318\n  otlphttp/dtmetrics:\n    endpoint: http://dynatrace-metrics-cluster-collector.dynatrace.svc.cluster.local:4318\n</code></pre> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p> <p>Query <code>astronomy-shop</code> metrics in Dynatrace</p> <p>DQL: <pre><code>timeseries jvm_mem_used = avg(jvm.memory.used), by: {service.name, k8s.cluster.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p> <p>DQL: <pre><code>timeseries avg(kafka.consumer.request_rate), by: {service.name, k8s.cluster.name}, filter: {k8s.namespace.name == \"astronomy-shop\"}\n</code></pre> Result:</p> <p></p> <p>Browse available metrics in Dynatrace</p> <p>You can browse all available metrics from OpenTelemetry sources in the Metrics Browser.  Filter on <code>Dimension:otel.scope.name</code> to find relevant metrics.</p> <p>Dynatrace Documentation</p> <p></p>"},{"location":"6-opentelemetry-metrics/#wrap-up","title":"Wrap Up","text":""},{"location":"6-opentelemetry-metrics/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect metrics, enrich metric attributes for better context, and ship those metrics to Dynatrace for analysis.</p> <ul> <li>One Community Contrib Distro OpenTelemetry Collector was deployed as a DaemonSet, behaving as an Agent running on each Node<ul> <li>The <code>kubeletstats</code> receiver scrapes metrics from the local kubelet on the Node</li> <li>The <code>k8sattributes</code> processor enriches the metrics with Kubernetes attributes that may be missing without it</li> </ul> </li> <li>A second Community Contrib Distro OpenTelemetry Collector was deployed as a Deployment, behaving as a Gateway<ul> <li>The <code>k8s_cluster</code> receiver queries the Kubernetes cluster API to retrieve metrics</li> <li>The <code>k8sattributes</code> processor enriches the metrics with Kubernetes attributes that may be missing without it</li> <li>The <code>otlp</code> receiver receives signals that are exported from agents, SDKs, and other Collectors</li> </ul> </li> <li>Metrics produced by the OpenTelemetry SDKs and Agents are exported to the <code>otlp</code> receiver</li> <li>Dynatrace DQL (via Notebooks) allows you to perform powerful queries and analysis of the metric data</li> </ul>"},{"location":"6-opentelemetry-metrics/#continue","title":"Continue","text":"<p>In the next section, we'll integrate and apply what we have learned in the OpenTelemetry Capstone.</p> <ul> <li>Continue to OpenTelemetry Capstone</li> </ul>"},{"location":"7-opentelemetry-capstone/","title":"7. OpenTelemetry Capstone","text":""},{"location":"7-opentelemetry-capstone/#opentelemetry-capstone","title":"OpenTelemetry Capstone","text":"<p>Capstone Module</p> <p>What is a Capstone? A hands-on, culminating learning experience where participants apply the knowledge and skills they've gained throughout a course or program to solve a real-world problem, create a project, or present a comprehensive solution.</p> <p>In this lab module we'll utilize multiple OpenTelemetry Collectors to collect application traces/spans, log records, and metric data points generated by OpenTelemetry, from a Kubernetes cluster and ship them to Dynatrace.  This is a capstone lab that utilizes the concepts of the previous Kubernetes OpenTelemetry lab modules.</p> <p>Lab tasks:</p> <ol> <li>Deploy 4 OpenTelemetry Collectors</li> <li>Configure OpenTelemetry Collector service pipeline for data enrichment</li> <li>Analyze metrics, traces, and logs in Dynatrace</li> <li>Observe OpenTelemetry Collector health in Dynatrace</li> </ol> <ul> <li>Learn More</li> </ul>"},{"location":"7-opentelemetry-capstone/#prerequisites","title":"Prerequisites","text":"<p>Import Dashboards into Dynatrace</p> <p> astronomy-shop dashboard</p> <p> collector health dashboard</p> <p>Define workshop user variables In your Github Codespaces Terminal set the environment variables:</p> <p>Sprint Environment</p> <p>Are you using a Sprint environment for your Dynatrace tenant?  If so, then use <code>export DT_ENDPOINT=https://{your-environment-id}.sprint.dynatracelabs.com/api/v2/otlp</code> instead of the <code>live</code> version below.</p> <pre><code>export DT_ENDPOINT=https://{your-environment-id}.live.dynatrace.com/api/v2/otlp\nexport DT_API_TOKEN={your-api-token}\nexport NAME=&lt;INITIALS&gt;-k8s-otel-o11y\n</code></pre> <p>Move into the metrics module directory</p> <p>Command: <pre><code>cd $BASE_DIR/lab-modules/dt-k8s-otel-o11y-capstone\n</code></pre></p> <p>Clean Up Previous Deployments</p> <p>Delete <code>dynatrace</code> namespace and all previous deployments</p> <p>Command: <pre><code>kubectl delete ns dynatrace\n</code></pre></p>"},{"location":"7-opentelemetry-capstone/#opentelemetry-operator-and-role-based-access","title":"OpenTelemetry Operator and Role Based Access","text":"<p>Deploy OpenTelemetry Operator</p> <p>Create <code>dynatrace</code> namespace</p> <p>Command: <pre><code>kubectl create namespace dynatrace\n</code></pre> Sample output:</p> <p>namespace/dynatrace created</p> <p>Create <code>dynatrace-otelcol-dt-api-credentials</code> secret</p> <p>The secret holds the API endpoint and API token that OpenTelemetry data will be sent to.</p> <p>Command: <pre><code>kubectl create secret generic dynatrace-otelcol-dt-api-credentials --from-literal=DT_ENDPOINT=$DT_ENDPOINT --from-literal=DT_API_TOKEN=$DT_API_TOKEN -n dynatrace\n</code></pre> Sample output:</p> <p>secret/dynatrace-otelcol-dt-api-credentials created</p> <p>Deploy <code>cert-manager</code>, pre-requisite for <code>opentelemetry-operator</code></p> <p>Cert Manager Documentation</p> <p>Command: <pre><code>kubectl apply -f opentelemetry/cert-manager.yaml\n</code></pre> Sample output:</p> <p>namespace/cert-manager created\\ customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\\ customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created</p> <p>Wait 30-60 seconds for cert-manager to finish initializing before continuing.</p> <p>Deploy <code>opentelemetry-operator</code></p> <p>The OpenTelemetry Operator will deploy and manage the custom resource <code>OpenTelemetryCollector</code> deployed on the cluster.</p> <p>Command: <pre><code>kubectl apply -f opentelemetry/opentelemetry-operator.yaml\n</code></pre> Sample output:</p> <p>namespace/opentelemetry-operator-system created\\ customresourcedefinition.apiextensions.k8s.io/instrumentations.opentelemetry.io created\\ customresourcedefinition.apiextensions.k8s.io/opampbridges.opentelemetry.io created\\ ...\\ validatingwebhookconfiguration.admissionregistration.k8s.io/opentelemetry-operator-validating-webhook-configuration configured</p> <p>Wait 30-60 seconds for opentelemetry-operator-controller-manager to finish initializing before continuing.</p> <p>Validate that the OpenTelemetry Operator components are running.</p> <p>Command: <pre><code>kubectl get pods -n opentelemetry-operator-system\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE opentelemetry-operator-controller-manager-5d746dbd64-rf9st 2/2 Running 0 1m <p>Create <code>clusterrole</code> with read access to Kubernetes objects</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector-k8s-clusterrole\nrules:\n  - apiGroups: ['']\n    resources: ['events', 'namespaces', 'namespaces/status', 'nodes', 'nodes/spec', 'nodes/stats', 'nodes/proxy', 'pods', 'pods/status', 'replicationcontrollers', 'replicationcontrollers/status', 'resourcequotas', 'services']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['apps']\n    resources: ['daemonsets', 'deployments', 'replicasets', 'statefulsets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['extensions']\n    resources: ['daemonsets', 'deployments', 'replicasets']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['batch']\n    resources: ['jobs', 'cronjobs']\n    verbs: ['get', 'list', 'watch']\n  - apiGroups: ['autoscaling']\n    resources: ['horizontalpodautoscalers']\n    verbs: ['get', 'list', 'watch']\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole.yaml\n</code></pre> Sample output:</p> <p>clusterrole.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole created</p> <p>Create <code>clusterrolebinding</code> for OpenTelemetry Collector service accounts</p> <p><pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector-k8s-clusterrole-crb\nsubjects:\n- kind: ServiceAccount\n  name: dynatrace-deployment-collector\n  namespace: dynatrace\n- kind: ServiceAccount\n  name: dynatrace-daemonset-collector\n  namespace: dynatrace\n- kind: ServiceAccount\n  name: contrib-deployment-collector\n  namespace: dynatrace\n- kind: ServiceAccount\n  name: contrib-daemonset-collector\n  namespace: dynatrace\nroleRef:\n  kind: ClusterRole\n  name: otel-collector-k8s-clusterrole\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/rbac/otel-collector-k8s-clusterrole-crb.yaml\n</code></pre> Sample output:</p> <p>clusterrolebinding.rbac.authorization.k8s.io/otel-collector-k8s-clusterrole-crb created</p>"},{"location":"7-opentelemetry-capstone/#dynatrace-deployment-collector","title":"Dynatrace Deployment Collector","text":"<p>OpenTelemetry Collector - Dynatrace Distro (Deployment)</p> <p>Dynatrace Documentation</p> <p>Receivers: <code>otlp</code>, <code>prometheus</code></p> MODULE DT DEPLOY DT DAEMON CON DEPLOY CON DAEMON otlp - [x] - [ ] - [x] - [ ] prometheus - [x] - [x] - [x] - [x] filelog - [ ] - [x] - [ ] - [ ] kubeletstats - [ ] - [ ] - [ ] - [x] k8s_cluster - [ ] - [ ] - [x] - [ ] k8sobjects - [ ] - [ ] - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p>Dynatrace Documentation <pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-deployment\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/dynatrace/otel-collector-dynatrace-deployment-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-deployment created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-deployment-collector-796546fbd6-kqflf 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#dynatrace-daemonset-collector","title":"Dynatrace Daemonset Collector","text":"<p>OpenTelemetry Collector - Dynatrace Distro (Daemonset)</p> <p>Dynatrace Documentation</p> <p>Receivers: <code>filelog</code>, <code>prometheus</code></p> MODULE DT DEPLOY DT DAEMON CON DEPLOY CON DAEMON otlp - [x] - [ ] - [x] - [ ] prometheus - [x] - [x] - [x] - [x] filelog - [ ] - [x] - [ ] - [ ] kubeletstats - [ ] - [ ] - [ ] - [x] k8s_cluster - [ ] - [ ] - [x] - [ ] k8sobjects - [ ] - [ ] - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p>Dynatrace Documentation</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: dynatrace-daemonset\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"daemonset\"\n  image: \"ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/dynatrace/otel-collector-dynatrace-daemonset-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/dynatrace-daemonset created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE dynatrace-daemonset-collector-h69pz 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#contrib-deployment-collector","title":"Contrib Deployment Collector","text":"<p>OpenTelemetry Collector - Contrib Distro (Deployment)</p> <p>Dynatrace Documentation</p> <p>Receivers: <code>otlp</code>, <code>prometheus</code>, <code>k8s_cluster</code>, <code>k8sobjects</code></p> MODULE DT DEPLOY DT DAEMON CON DEPLOY CON DAEMON otlp - [x] - [ ] - [x] - [ ] prometheus - [x] - [x] - [x] - [x] filelog - [ ] - [x] - [ ] - [ ] kubeletstats - [ ] - [ ] - [ ] - [x] k8s_cluster - [ ] - [ ] - [x] - [ ] k8sobjects - [ ] - [ ] - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p>OpenTelemetry Documentation</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: contrib-deployment\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"deployment\"\n  image: \"otel/opentelemetry-collector-contrib:0.103.0\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/contrib/otel-collector-contrib-deployment-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/contrib-deployment created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE contrib-deployment-collector-74dfc4d9f4-s97k6 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#contrib-daemonset-collector","title":"Contrib Daemonset Collector","text":"<p>OpenTelemetry Collector - Contrib Distro (Daemonset)</p> <p>Receivers: <code>prometheus</code>, <code>kubeletstats</code></p> MODULE DT DEPLOY DT DAEMON CON DEPLOY CON DAEMON otlp - [x] - [ ] - [x] - [ ] prometheus - [x] - [x] - [x] - [x] filelog - [ ] - [x] - [ ] - [ ] kubeletstats - [ ] - [ ] - [ ] - [x] k8s_cluster - [ ] - [ ] - [x] - [ ] k8sobjects - [ ] - [ ] - [x] - [ ] <p>Deploy OpenTelemetry Collector CRD</p> <p><pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: contrib-daemonset\n  namespace: dynatrace\nspec:\n  envFrom:\n  - secretRef:\n      name: dynatrace-otelcol-dt-api-credentials\n  mode: \"daemonset\"\n  image: \"otel/opentelemetry-collector-contrib:0.103.0\"\n</code></pre> Command: <pre><code>kubectl apply -f opentelemetry/collector/contrib/otel-collector-contrib-daemonset-crd.yaml\n</code></pre> Sample output:</p> <p>opentelemetrycollector.opentelemetry.io/contrib-daemonset created</p> <p>Validate running pod(s)</p> <p>Command: <pre><code>kubectl get pods -n dynatrace\n</code></pre></p> <p>Sample output:</p> NAME READY STATUS RESTARTS AGE contrib-daemonset-collector-d92tw 1/1 Running 0 1m"},{"location":"7-opentelemetry-capstone/#configure-astronomy-shop-otlp-export","title":"Configure Astronomy Shop OTLP Export","text":"<pre><code>config:\n    receivers:\n      otlp:\n        protocols:\n          http:\n            # Since this collector needs to receive data from the web, enable cors for all origins\n            # `allowed_origins` can be refined for your deployment domain\n            cors:\n              allowed_origins:\n                - \"http://*\"\n                - \"https://*\"\n      httpcheck/frontendproxy:\n        targets:\n          - endpoint: 'http://{{ include \"otel-demo.name\" . }}-frontendproxy:8080'\n\n    exporters:\n      # Dynatrace OTel Collector\n      otlphttp/dynatrace:\n        endpoint: http://dynatrace-deployment-collector.dynatrace.svc.cluster.local:4318\n\n    processors:\n      resource:\n        attributes:\n        - key: service.instance.id\n          from_attribute: k8s.pod.uid\n          action: insert\n\n    connectors:\n      spanmetrics: {}\n\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [memory_limiter, resource, batch]\n          exporters: [spanmetrics, otlphttp/dynatrace]\n        metrics:\n          receivers: [httpcheck/frontendproxy, otlp, spanmetrics]\n          processors: [memory_limiter, resource, batch]\n          exporters: [otlphttp/dynatrace]\n        logs:\n          processors: [memory_limiter, resource, batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre> <p>Export OpenTelemetry data from <code>astronomy-shop</code> to OpenTelemetry Collector - Dynatrace Distro (Deployment)</p> <p>Customize astronomy-shop helm values</p> <pre><code>default:\n  # List of environment variables applied to all components\n  env:\n    - name: OTEL_SERVICE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: \"metadata.labels['app.kubernetes.io/component']\"\n    - name: OTEL_COLLECTOR_NAME\n      value: '{{ include \"otel-demo.name\" . }}-otelcol'\n    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE\n      value: cumulative\n    - name: OTEL_RESOURCE_ATTRIBUTES\n      value: 'service.name=$(OTEL_SERVICE_NAME),service.namespace=NAME_TO_REPLACE,service.version={{ .Chart.AppVersion }}'\n</code></pre> <p>service.namespace=NAME_TO_REPLACE\\ service.namespace=INITIALS-k8s-otel-o11y</p> <p>Command: <pre><code>sed -i \"s,NAME_TO_REPLACE,$NAME,\" astronomy-shop/collector-values.yaml\n</code></pre></p> <p>Update <code>astronomy-shop</code> OpenTelemetry Collector export endpoint via helm</p> <p>Command: <pre><code>helm upgrade astronomy-shop open-telemetry/opentelemetry-demo --values astronomy-shop/collector-values.yaml --namespace astronomy-shop --version \"0.31.0\"\n</code></pre> Sample output:</p> <p>NAME: astronomy-shop\\ LAST DEPLOYED: Thu Jun 27 20:58:38 2024\\ NAMESPACE: astronomy-shop\\ STATUS: deployed\\ REVISION: 2</p>"},{"location":"7-opentelemetry-capstone/#validate-and-analyze-data-in-dynatrace","title":"Validate and Analyze Data in Dynatrace","text":"<p>Analyze metrics, traces, and logs in Dynatrace dashboard</p> <p> astronomy-shop dashboard</p>"},{"location":"7-opentelemetry-capstone/#opentelemetry-collector-health","title":"OpenTelemetry Collector Health","text":""},{"location":"7-opentelemetry-capstone/#observe-opentelemetry-collector-health-in-dynatrace","title":"Observe OpenTelemetry Collector health in Dynatrace","text":"<p>OpenTelemetry Documentation</p> <ul> <li>Add <code>dynatrace.otel.collector</code> to Dynatrace's metric attribute allow list</li> <li>Enable OpenTelemetry Collector health metrics (Prometheus)</li> <li>Modify OpenTelemetry Collector health metrics for Dynatrace support</li> <li>View OpenTelemetry Collector health metrics in Dynatrace</li> </ul> <p>Add <code>dynatrace.otel.collector</code> to Dynatrace's metric attribute allow list</p> <p>By default, the metric attribute <code>dynatrace.otel.collector</code> is dropped by Dynatrace.  Add it to the allow list in your Dynatrace tenant:</p> <p>Dynatrace Documentation </p> <p>Enable OpenTelemetry Collector health metrics (Prometheus)</p> <p>Enable metric generation for Collector CRD: <pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  namespace: dynatrace\nspec:\n  observability:\n    metrics:\n      enableMetrics: true\n</code></pre></p> <p>Enable publishing of metric generation to Prometheus endpoint: <pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  namespace: dynatrace\nspec:\n  env:\n    - name: MY_POD_IP\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: status.podIP\n  config: |\n    receivers:\n\n    processors:\n\n    exporters:\n\n    service:\n      telemetry:\n        metrics:\n          level: \"normal\"\n          address: ${MY_POD_IP}:8888\n</code></pre></p> <p>Enable scraping of metrics from Prometheus endpoint: <pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  namespace: dynatrace\nspec:\n  config: |\n    receivers:\n      prometheus:\n        config:\n          scrape_configs:\n          - job_name: opentelemetry-collector\n            scrape_interval: 30s\n            static_configs:\n            - targets:\n              - ${MY_POD_IP}:8888\n\n    processors:\n      batch:\n\n    exporters:\n      otlphttp/dynatrace:\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [prometheus]\n          processors: [batch]\n          exporters: [otlphttp/dynatrace]\n</code></pre></p> <p>Modify OpenTelemetry Collector health metrics for Dynatrace support</p> <p>Specific metric types are supported by Dynatrace:</p> <p>Dynatrace Documentation</p> <p>Convert unsupported cumulative sum metric types to delta type for Dynatrace support: <pre><code>processors:\n  cumulativetodelta: {}\nservice:\n  pipelines:\n  metrics:\n    receivers: [prometheus]\n    processors: [cumulativetodelta,batch]\n    exporters: [otlphttp/dynatrace]\n</code></pre></p> <p>Histogram Metric Support</p> <p>In a recent update, Dynatrace added support for histogram metrics.  This configuration is no longer required.  However, it may still be useful to see how this can be accomplished.</p> <p>Filter out (remove) unsupported histogram metric types for Dynatrace support: <pre><code>processors:\n  filter/histogram:\n    error_mode: ignore\n    metrics:\n      metric:\n      - 'type == METRIC_DATA_TYPE_HISTOGRAM'\n\nservice:\n  pipelines:\n  metrics:\n    receivers: [prometheus]\n    processors: [filter/histogram,batch]\n    exporters: [otlphttp/dynatrace]\n</code></pre></p> <p>View OpenTelemetry Collector health metrics in Dynatrace</p> <p>Prometheus metrics from the OpenTelemetry Collector have the <code>otelcol_</code> prefix and can be found in the Dynatrace metric browser: </p> <p>Example dashboard for OpenTelemetry Collector health has been created by the <code>IsItObservable</code> team: </p> <p>YouTube Video</p>"},{"location":"7-opentelemetry-capstone/#wrap-up","title":"Wrap Up","text":""},{"location":"7-opentelemetry-capstone/#what-you-learned-today","title":"What You Learned Today","text":"<p>By completing this lab, you've successfully deployed the OpenTelemetry Collector to collect metrics, traces, and logs from Kubernetes and ship them to Dynatrace for analysis.</p> <ul> <li>The Dynatrace Distro of OpenTelemetry Collector includes supported modules needed to ship telemetry to Dynatrace<ul> <li>The <code>otlp</code> receiver receives metrics, traces, and logs from OpenTelemetry exporters via gRPC/HTTP</li> <li>The <code>filelog</code> receiver scrapes logs from the Node filesystem and parses the contents</li> <li>The <code>prometheus</code> receiver scrapes metric data exposed by Pod Prometheus endpoints</li> </ul> </li> <li>The Contrib Distro of OpenTelemetry Collector includes additional modules needed to ship telemetry to Dynatrace<ul> <li>The <code>kubeletstats</code> receiver scrapes metrics from the local kubelet on the Node</li> <li>The <code>k8s_cluster</code> receiver queries the Kubernetes cluster API to retrieve metrics</li> <li>The <code>k8sobjects</code> receiver watches for Kubernetes events (and other resources) on the cluster</li> </ul> </li> <li>Dynatrace allows you to perform powerful queries and analysis of the telemetry data</li> <li>Observing the health of the OpenTelemetry Collectors and data pipeline is critical<ul> <li>The OpenTelemetry Collector exposes self-monitoring metrics in Prometheus format</li> </ul> </li> </ul>"},{"location":"7-opentelemetry-capstone/#continue","title":"Continue","text":"<p>Now that the lab has been completed, let's summarize what we have learned and clean up our Codespaces instance.</p> <ul> <li>Continue to cleanup</li> </ul>"},{"location":"cleanup/","title":"8. Cleanup","text":""},{"location":"cleanup/#clean-up","title":"Clean Up","text":""},{"location":"cleanup/#summary","title":"Summary","text":"<p>OpenTelemetry is a powerful observability framework that can be used to monitor the health of Kubernetes clusters and containerized workloads.</p> <p>Instrumentation: OpenTelemetry provides libraries and agents to instrument your Kubernetes applications. This means adding code to your applications to collect telemetry data such as traces, metrics, and logs.</p> <p>Data Collection: Once instrumented, OpenTelemetry collects telemetry data from your applications running in the Kubernetes cluster. This data includes information about application performance, resource usage, and error rates.</p> <p>Exporters: OpenTelemetry supports various exporters to send the collected telemetry data to different backends for analysis. Using the OpenTelemetry Collector is the preferred approach to shipping this data to Dynatrace.</p> <p>Visualization and Analysis: By exporting telemetry data to Dynatrace, you can visualize and analyze the health of your Kubernetes cluster. For example, you can use DQL to create dashboards that display metrics like CPU usage, memory consumption, and request latency.</p> <p>Alerting: With the collected data, you can set up alerts to notify you of any issues in your Kubernetes cluster. For instance, you can configure alerts for high error rates or resource exhaustion.</p> <p>By using OpenTelemetry in this way, you can gain deep insights into the performance and health of your Kubernetes clusters, helping you to identify and resolve issues more effectively.</p>"},{"location":"cleanup/#references","title":"References","text":"<p>Dynatrace OpenTelemetry</p> <p>Dynatrace OpenTelemetry Collector</p> <p>Dynatrace OpenTelemetry Collector Use Cases</p> <p>OpenTelemetry Demo Astronomy Shop</p>"},{"location":"cleanup/#delete-codespaces-instance","title":"Delete Codespaces Instance","text":"<p>Deleting the codespace from inside the container</p> <p>We like to make your life easier, for convenience there is a function loaded in the shell of the Codespace for deleting the codespace, just type <code>deleteCodespace</code>. This will trigger the deletion of the codespace.</p> <p>Another way to do this is by going to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token needed for this lab.</p>"},{"location":"snippets/admonitions/","title":"Admonitions","text":"<p>Note</p> <p>This is a Note </p> <p>Abstract</p> <p>This is an abstract</p> <p>Tipp</p> <p>This is a tipp </p> <p>Success</p> <p>This is a success </p> <p>Question</p> <p>This is a success </p> <p>Failure</p> <p>This is a failure </p> <p>Danger</p> <p>This is a danger </p> <p>Info</p> <p>This is a info</p> <p>Warning</p> <p>This is a Warning </p> <p>This is an Example admonition</p> <p>This is an example</p> This is a bug and is collapsable <p>This is a bug</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy</p> <p>This is an enablement project created by the Center of Excellence - Enablement Team at Dynatrace.</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"snippets/requirements/","title":"Requirements","text":"<p>Requirements</p> <ul> <li>A Dynatrace SaaS Tenant with DPS license (sign up here)<ul> <li>Live, Sprint, or Dev environment</li> <li>Full administrator access to the account and tenant</li> </ul> </li> <li>A GitHub account to interact with the demo repository and run a Codespaces instance<ul> <li>Codespaces core-hours and storage available (GitHub Billing &amp; Licensing)</li> </ul> </li> </ul>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}